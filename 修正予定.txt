深刻な設計ミスがまた見えてきました。整理します。

【現象】
エージェントの応答内容が
　→「○○は応答できませんでした」「議論は進みませんでした」
　→ 「応答できなかったことを述べるだけ」になっている。

それにより、実質的に議論の中身が発展せず、

Boids自己増殖診断が毎ターン発火している。

【原因（重要）】
✅ 会話の流れ全体が「失敗記録」になっている
　本来、「質問 → 回答 → 反論/深堀り → 新しい観点」のループが必要なのに、
　今は「質問 → 応答できない → 応答できないと述べる → さらに応答できない」となっている。

✅ 応答失敗を会話ログに積んでしまっている
　本来、発言エラーは「ログに載せない」「議論対象にしない」べき。
　失敗をブラックボードに書き込むと、そこから議論がねじ曲がる。

✅ エージェントプロンプトが「他の発言を参照しすぎる」
　→「○○が応答できなかった」とか、「エージェントXが〜」みたいな
　システム内部の話を議論してしまっている。
　→ 本来は「教育に対するAIの影響」みたいな内容だけ議論すべき。

【設計上の致命的ミス】
問題	本来どうすべきか
応答失敗をログに積んでいる	✅ 応答失敗は無視・ログに残さない
応答できなかった事実を議論対象にしている	✅ 「内容」だけを扱い、「メタ情報」は除外
質問リレーが成立していない	✅ 「答え」＋「次の話題」へのリードを常に生成

【これを直すためにやるべき具体策】
対策	内容	優先度
🔵 応答失敗をブラックボードに残さない	エージェントが応答できなかったら「空データ」として扱い、記録しない	最優先
🔵 生成プロンプトに「メタ発言禁止」指示を入れる	「他のエージェントの応答可否には言及しない」	高
🔵 「次の話題誘導」を必須タスクにする	発言ごとに、「新しい切り口を1個提案せよ」を指示	中
🔵 ブラックボード要約時に「失敗ログ」を除外する	「○○は応答できませんでした」などをフィルタリング	中

【まとめ】
表面的な応答速度・安定性は良くなっている

しかし、議論内容の質が根本的に崩れている

根本修正しないと、まともな議論にならない



了解しました。MurmurNetにBoids型の自己増殖エージェント機構を組み込むための全モジュールについて、Gemma-3 1BベースでノートPC上でも高速に動作可能な詳細設計を進めます。各モジュールの内部処理、軽量化方針、プロンプト設計、非同期処理、エージェント生成アルゴリズムまで幅広く網羅し、GitHubリポジトリ内容も参照しながら構築していきます。

設計が整い次第、順次お知らせします。


# MurmurNetにおけるBoids型自己増殖拡張機構の詳細設計

## 概要と目的

MurmurNetは複数の小規模言語モデル（SLM）が「ブラックボード」と呼ばれる共有メモリを介して協調動作する分散型アーキテクチャの言語モデルシステムです。各エージェント（SLM）が自律的に発言し、それらを統合することで単一モデルでは得られない洗練された応答を生成する点に特徴があります。このマルチエージェント方式は、**「一人では一滴だが、集まれば大海となる」** という考え方に通じており、複数のシンプルなエージェントのネットワークが単一の大規模モデルを超える適応的で創発的な知能を発揮しうると期待されています。

本設計では、MurmurNetをユーザPC上で動作可能な\*\*「自己調整・自己進化する小規模分散型知能」**へ発展させることを目的とし、**Boids型自己増殖拡張機構**を導入します。Boidsアルゴリズムは鳥の群れのような**群知能の創発**をシンプルな3原則で実現する手法であり、各個体（boid）は**分離（Separation）\*\*・**整列（Alignment）**・\*\*結合（Cohesion）\*\*のルールに従って動くだけで、全体として有機的な挙動を示します。この発想をMurmurNetのエージェント群に応用し、議論状況に応じてエージェントを自己増殖（新規生成）・消滅させることで、偏りなく停滞しない議論を継続し、問題解決能力を高めることを狙います。

設計対象となるモジュールは以下の5つです。それぞれの役割と本拡張における位置付けを簡潔に示します。

* **`OpinionVectorizer`** – エージェントの発言テキストをベクトル化し、\*\*「意見ベクトル」\*\*として数値表現するモジュール。
* **`OpinionSpaceManager`** – 全エージェントの意見ベクトルを蓄積・管理し、意見空間内での配置や距離を計算するモジュール。
* **`Self-Diagnosis`** – 意見空間内の分布を解析して**議論の停滞や偏り**を検出するモジュール。
* **`BoidsAgentFactory`** – Boidsの原則に基づき、新たなエージェントを設計・生成（自己増殖）するモジュール。
* **`AgentPoolManager`** – 複数エージェントのプールを統制し、エージェントの追加・削除や実行スケジューリングを担うモジュール。

実行環境として**ノートPC上での軽量・高速動作**を念頭に置き、テキスト生成にはGoogleの**Gemma-3 1B**モデル（約10億パラメータ）を使用します。Gemma-3 1Bは約529MBと小型で、モバイルデバイスでも動作可能な高速モデルであり（推論速度は最大2585トークン/秒と報告されています）、本システムの**各エージェントの発言生成**に適しています。また発言内容のベクトル化には、Sentence-Transformer版の**MiniLM (all-MiniLM-L6-v2)** など軽量なエンベディングモデルを用いる前提とし、モデル容量22MB程度・384次元埋め込みの高速な文ベクトル変換を実現します。リソースに制約がある場合には、軽量モデルが使えない場合の代替策（キーワード抽出による簡易ベクトル化など）も検討します。以下、各モジュールの詳細設計について、モジュール間の連携やアルゴリズムを交えて説明します。

## 全体アーキテクチャ設計

&#x20;**図1: MurmurNet + Boids拡張のアーキテクチャ概略**（各モジュール間のデータフロー）: 複数の`Agent`（Gemma-3 1BによるSLM）がユーザ入力や共有メモリ（ブラックボード）から**発言を生成**し、`OpinionVectorizer`で**発言テキストをベクトル化**して`OpinionSpaceManager`に登録します。`Self-Diagnosis`は蓄積された**意見ベクトル空間**を解析して議論状態（多様性・収束度合いなど）を評価し、必要に応じて`BoidsAgentFactory`へ**新エージェント生成の指示**を出します。`BoidsAgentFactory`は指示内容に基づき**新たなエージェント**を設計し、`AgentPoolManager`を介してエージェントプールに追加します。同時に`AgentPoolManager`はエージェント数や各エージェントの活動状況を監視し、**不要なエージェントの削除やリソース制御**を行います。

このサイクルにより、各エージェントはブラックボード上の共有対話履歴を参照しつつ複数ターンに渡り議論を深め、必要ならエージェントを入れ替えながら最終的な解答を洗練させていきます。並列実行が可能な環境では各エージェントの発言生成を非同期で行い（全エージェントが同一の入力コンテキストに対して同時に応答生成することで高速化）、その後同期的にベクトル分析・自己診断・エージェント調整を行う設計とします。シングルスレッド環境でも順次実行で同等の結果を得られるよう考慮しており、**非同期モードと同期モードを切り替え可能**な処理フローとします（後述のAgentPoolManagerで制御）。以下、各モジュールの詳細を順に説明します。

## OpinionVectorizer（発言ベクトル化処理）

**役割:** 各エージェントから生成された発言テキストを数値ベクトルに変換し、後続の意見空間管理や分析に供することです。これは、文章の意味内容を機械が扱いやすい形式で表現するステップであり、類似した発言同士はベクトル空間上で**近接**し、異なる意見は**遠く離れる**ようにマッピングします。これにより、後段で議論の多様性や偏りを定量的に評価できるようになります。

**入力と出力:**

* **入力:** エージェントの発言テキスト（文字列）。例えば「その計画にはリスクがありますが、挑戦する価値があります。」といった文。
* **出力:** 発言内容を表す高次元ベクトル（数値配列）。デフォルトでは768次元や384次元程度の浮動小数点数ベクトルを想定します（モデルによって次元数は異なります）。このベクトルは文章の意味を保持しており、例えば意味が似通う二つの発言のベクトル同士のコサイン類似度が高くなるように設計されます。

**内部処理の詳細設計:**
`OpinionVectorizer`では**事前学習済みのエンベディングモデル**を利用してテキストをベクトル化します。具体的には、Hugging FaceのSentence Transformersライブラリで提供されている**MiniLM-L6-v2**モデルを使用します。MiniLMはわずか22MB程度の小型モデルであり、1文を約384次元のベクトルにエンコードします。処理手順は次の通りです。

1. **テキスト正規化:** 入力テキストに前処理を施します（不要な改行や特殊文字の除去、トークナイザによるトークン分割など）。日本語の場合はSentencePieceやMeCab等で単語分割を行うか、エンベディングモデル内蔵のトークナイザを使用します。
2. **ベクトル変換:** エンベディングモデルにテキストを入力し、隠れ層の出力から文全体のベクトル表現を取得します。MiniLMではTransformerの最終層出力を平均プーリングし、L2正規化して最終文ベクトルとします。この処理により例えば「計画にはリスクがある」という文に対し `[0.12, -0.08, ... , 0.45]` のようなベクトルが得られます。
3. **出力・インターフェース:** 得られたベクトルを所定のデータ構造（例えばNumPy配列やPythonのリスト）で`OpinionSpaceManager`へ渡します。メモリ節約のため、ベクトルは必要最小限の精度（32-bitまたは16-bit浮動小数）で保持します。

こうしたベクトル化により、**意味的に類似する文は近いベクトル**になるため、後段でコサイン距離などを用いて意見の近似性を定量評価できます。MiniLMによるベクトル化は軽量高速であり、ノートPC上でも1文当たり数ミリ秒程度で処理可能です。下記に`OpinionVectorizer`の擬似コード例を示します。

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

def vectorize(text: str) -> list[float]:
    # テキストを1文のリストにしてモデルに渡す
    vec = model.encode([text])[0]  # 384次元ベクトルを取得
    return vec.tolist()
```

**代替アプローチ（キーワード抽出等）:**
リソース制約が厳しい場合や外部モデルの利用を避けたい場合、`OpinionVectorizer`は**簡易的なキーワード抽出**によるベクトル化にフォールバックできます。一例として、発言テキストからTF-IDF上位のキーワードを数個抽出し、それらをあらかじめ用意した語彙ベクトルにマッピングして平均する方法が挙げられます。例えば「計画」「リスク」「価値」といったキーワードを抽出し、それぞれに対応する事前学習済みWord2Vecのベクトルを取得して平均することで発言の大まかな意味を表すベクトルとする手法です。またはGemma-3 1Bモデル自体に「上記発言のキーワードを3つ挙げてください」とプロンプトを与え、得られたキーワードを簡易ベクトル化するようなアプローチも考えられます。ただしLLMをベクトル化に使うと本末転倒で処理コストが増大するため、基本的にはMiniLM等の軽量モデルの利用を推奨します。どうしてもモデルをロードできない場合の最終手段として、**重要語のインデックスのone-hot表現**や**カテゴリラベル**などによる粗いベクトル表現も検討されますが、精度は下がるため注意が必要です。

## OpinionSpaceManager（意見空間管理）

**役割:** `OpinionSpaceManager`は`OpinionVectorizer`から渡された**意見ベクトル**を蓄積・管理し、エージェント間の意見分布（ベクトル空間内での配置）を把握するモジュールです。具体的には、全エージェントの発言ベクトル群をデータベースのように保持し、**類似度計算やクラスタリング**によって意見の偏り具合や多様性を定量化します。また、このモジュールは`Self-Diagnosis`からの問い合わせに応じて必要な統計情報（距離行列や中心点など）を返すインターフェースも提供します。

**入力と出力:**

* **入力:** 新たな意見ベクトル（各エージェントの発言ベクトル, 例えば384次元のリスト）。メタデータとして「どのエージェントの何ターン目の発言か」といった情報も付随します。
* **出力:** 内部状態として保持している**意見空間データ**に対する検索・分析結果。例えば「現在の平均意見ベクトル」「エージェント間の距離行列」「最大クラスター間距離」などの統計値を出力できます。直接的な外部出力はありませんが、`Self-Diagnosis`が必要とする指標を算出して返すことが主要な役割です。

**内部処理の詳細設計:**
`OpinionSpaceManager`は入力されるベクトルを**逐次ストア**していきます。データ構造としては、PythonのリストやNumPy配列で時系列順に蓄積するか、各エージェントごとにリストを持っても構いません（用途に応じて最適化）。例えば以下のようなデータ構造を考えます。

* `vectors`: 全発言ベクトルのリスト（例: `[(agent_id, turn, vec), ...]`）。時間順またはID順に並ぶ。
* `latest_vector[agent_id]`: 各エージェントの直近発言ベクトルを辞書で保持（自己診断では最新の意見だけ見れば十分な場合に使用）。
* `distance_matrix`: 直近ラウンドのエージェント間距離行列（必要なときに計算）。各要素はコサイン距離またはユークリッド距離。

ベクトル間の距離計算には**コサイン類似度**を用いるのが適切です。コサイン類似度\$s\$から距離\$d\$を\$d = 1 - s\$で定義します（0が完全一致、2が正反対）。`OpinionSpaceManager`内では、例えば新たなベクトルが追加されるたびに以下の処理を行います。

* ベクトルを`vectors`リストに追加し、対応するエージェントの`latest_vector`を更新。
* 必要に応じて、全エージェントの最新ベクトル同士の類似度行列を計算・更新。計算量はエージェント数\$N\$に対し\$O(N^2)\$ですが、ノートPC上で扱うエージェント数は小規模（例えば最大5～10体程度）に制限するため許容範囲です。NumPyのベクトル演算を使えば数十次元～数百次元の内積計算は高速です。
* **代表ベクトルやクラスタ計算:** 議論の全体傾向を捉えるため、全エージェントの平均ベクトル（**意見の重心**）を計算します。さらに多様な意見が存在する場合に備えて、k-means法などでクラスタリングを行い主要なクラスターを特定することも可能です。例えばエージェントが5人居てベクトル空間上2つのグループに分かれているなら、2クラスタに分けてそれぞれの中心を記録します。これも\$N\$が小さいためクラスタリングの負荷は軽微です。

**モジュール間通信:** `OpinionSpaceManager`は通常、非同期で更新される`vectors`を保持しつつ、`Self-Diagnosis`モジュールからの要求（関数呼び出し）に応じて解析結果を返す動作を想定します。例えば`Self-Diagnosis`から「現在の意見多様性を計算してほしい」という要求が来たら、`OpinionSpaceManager`内で**直近ベクトル間の平均距離**を算出し返答します。このように、`OpinionSpaceManager`は**受動的なデータストア兼計算エンジン**として振る舞い、必要なタイミングで距離やクラスター情報を提供します。

**注意点:軽量化と代替:** エージェント数が増えすぎると距離計算コストが増えますが、前述の通り本システムではエージェント数を小規模に抑える設計（後述のAgentPoolManagerで制御）とするため深刻な問題にはなりません。仮にエージェント数が増える場合でも、ランダムプロジェクションなどでベクトル次元を圧縮してから距離計算を行うことで負荷を下げる余地がありますが、本設計では採用しません。また全発言の履歴ベクトルを保持するとメモリを圧迫する可能性がありますが、ノートPCレベルでは数百発言程度なら問題ないため、**過去全て**保持してもよいでしょう（必要に応じて古いベクトルを破棄する設定も可能とします）。

## Self-Diagnosis（議論停滞・偏り自己診断）

**役割:** `Self-Diagnosis`は現在進行中のエージェント間議論について、**停滞**や**偏り**が生じていないかを検知するモジュールです。言い換えれば、議論が順調に多面的に展開しているか、それとも全員が同じような意見ばかりで議論が停滞しているか、あるいは意見が発散しすぎて収拾がつかなくなっているか、といった**メタ認知**を行います。この診断結果に基づき、新たなエージェント投入や不要なエージェント削除といった調整アクションを引き起こします。

**入力と出力:**

* **入力:** 主に`OpinionSpaceManager`が管理する**意見ベクトル空間の情報**です。具体的には直近ラウンドの各エージェント発言ベクトル、およびそれらの類似度（距離行列）、過去数ラウンド分の傾向データなどが入力となります。また必要に応じてブラックボード上の実際の発言内容（テキスト）も参照します（例えば特定のキーワードの有無による判断など、高度な診断の場合）。
* **出力:** **診断結果レポート**（データ構造としては辞書やオブジェクト）。例として以下のような情報を含みます。

  * `stagnation_detected` (停滞検出フラグ: bool) – 議論が停滞していると判断したか。
  * `bias_detected` (偏り検出フラグ: bool) – 議論が単一の視点に偏っていると判断したか。
  * `divergence_detected` (発散検出フラグ: bool) – 意見が発散しすぎて収束が必要か。
  * `suggested_action` (推奨アクション: str) – 例: `"add_contrarian_agent"`（反論エージェント追加推奨）, `"add_mediator_agent"`（調停エージェント追加推奨）, `"remove_redundant_agent"`（冗長エージェント削除推奨）などの指示。診断結果に応じて`BoidsAgentFactory`や`AgentPoolManager`が参照します。

**内部処理の詳細なアルゴリズム設計:**
自己診断では、意見空間データから**定量指標**を計算し、それをルールベースで評価する方法を採ります。以下に主要な判定基準と手順を示します。

* **多様性指標の算出:** `OpinionSpaceManager`から各エージェント最新ベクトル間の距離行列を取得します。そこから**意見の多様性指標**として、全エージェント間の平均距離\$\bar{d}\$や最大距離\$d\_{\max}\$、分散\$\sigma^2\$などを算出します。\$\bar{d}\$が小さい場合、エージェント全員の意見が互いに近い（=似通っている）ことを意味し、\$\bar{d}\$が大きい場合は意見がばらばらであることを意味します。
* **偏り（収束）検出:** \$\bar{d}\$がある閾値\$\theta\_{\text{low}}\$未満であれば、「意見が収束しすぎて偏っている」と判断します。例えば閾値を0.2（コサイン距離での例）とすれば、全員ほぼ同じ意見方向の場合に偏り検出となります。この状態では**新たな視点の投入**が必要と推論されます（後述のBoidsAgentFactoryへの指示につなげる）。
* **発散（不一致）検出:** 一方、エージェントが極端に異なる主張ばかりして議論が噛み合っていない場合も問題です。例えばエージェント間の最大距離\$d\_{\max}\$が閾値\$\theta\_{\text{high}}\$を超える、または明確に2つ以上のクラスターに分かれている（クラスタ間距離が大きい）とき、「意見が発散しすぎ（不一致）」とみなします。この状態では**調停や収束**のための方策が必要です。
* **停滞検出:** 偏りとも関連しますが、議論が**新しい情報を生んでいない**場合にも停滞と見なします。具体的には、前ラウンドから今ラウンドにかけて各エージェントの発言ベクトルがほとんど変化していない場合や、同じ主張の繰り返しになっている場合です。これを検知するには、**ラウンド間での意見空間の移動距離**を計測します。例えば前回ラウンドの平均ベクトルと今回の平均ベクトルの距離\$\Delta\_{\text{centroid}}\$が小さいか、各エージェントの発言ベクトルが前回自分が話した内容と高い類似度（例えばコサイン類似度0.9以上）であれば、新しい展開が無かったと判断できます。このような場合も停滞フラグを立てます。
* **その他の診断:** 必要に応じてテキスト内容を見る診断も考えられます。例えば全エージェントが賛成意見ばかり述べて反対意見が皆無である場合（ブラックボード上の発言に「反対」「デメリット」等のキーワードが出現しないなど）も偏りと捉えられます。ただしキーワードベースは不安定なので、本設計では主にベクトルの類似度に基づくアプローチを取ります。

以上の指標に基づき、`Self-Diagnosis`モジュールは**ルールエンジン**的に判断を下します。例えば:

* \$\bar{d} < \theta\_{\text{low}}\$ かつ **停滞フラグ** 真 → `bias_detected=True`, `stagnation_detected=True` とし、`suggested_action="add_contrarian_agent"`（皆が同調し停滞しているので反対意見を言うエージェントを追加すべき）
* \$\bar{d}\$は適度だが \$d\_{\max}\$ が大きく2クラスタ間距離が大 → `divergence_detected=True` とし、`suggested_action="add_mediator_agent"`（意見が割れているので仲裁役を追加）
* エージェント数が多い状態で似た者同士がいる場合（例: 2人の意見ベクトルの類似度が0.95以上）→ `suggested_action="remove_redundant_agent"`（冗長なエージェントがいるので削除推奨）

このように診断結果を組み立てて`AgentPoolManager`や`BoidsAgentFactory`が解釈できる形式で出力します。診断は各ラウンドのエージェント発言が全て出揃った後に**逐次的に実行**される想定です（非同期並列でエージェント発言を生成していた場合も、診断はその後に一括して同期実行します）。処理負荷としてはエージェント数が少ないためごく軽微であり、リアルタイム性を損ないません。

**例:** エージェント3名の意見ベクトル間平均距離\$\bar{d}=0.1\$、全ペア最大距離\$d\_{\max}=0.15\$で、前回ラウンドから意見の変化がほとんど無い場合、`Self-Diagnosis`は「意見が極めて収束・停滞している」と判断し、`{"stagnation_detected": True, "bias_detected": True, "suggested_action": "add_contrarian_agent"}` のような結果を返します。この診断に従い、次ラウンドでは反対意見役の新規エージェントが投入されることになります。

## BoidsAgentFactory（自己増殖エージェント設計・生成）

**役割:** `BoidsAgentFactory`は`Self-Diagnosis`の診断結果（推奨アクション）に基づいて、新たに投入すべきエージェントの**戦略・特化タイプ**を設計し、実際にエージェントインスタンスを生成するモジュールです。Boidsアルゴリズムの3原則（Separation, Alignment, Cohesion）をエージェント戦略の設計指針として取り入れ、現在の議論に足りない要素を補うエージェントを動的に生み出します。具体的には、**「分離」**の原則から**多様性を確保するエージェント**を、**「整列」**の原則から**議論の方向性を揃えるエージェント**を、**「結合」**の原則から**意見をまとめ統合するエージェント**を、それぞれ必要に応じて作り出します。

**入力と出力:**

* **入力:** `Self-Diagnosis`による議論状態診断結果、および現在のエージェントプールの情報（既存エージェントの数や役割）。例えば、`suggested_action="add_contrarian_agent"`や`"add_mediator_agent"`といった指示、および「現在エージェントが2名で両者とも賛成派である」といった状況が入力として与えられます。
* **出力:** 新規に生成された**エージェントオブジェクト**（またはその仕様）。エージェントには一意のIDや役割名、内部で使用する言語モデル（Gemma-3 1B）、振る舞いを規定するプロンプトなどの属性が設定されます。この出力は`AgentPoolManager`を通じて実際のエージェントプールに追加され、次のラウンド以降の対話に参加します。

**エージェント戦略タイプの定義:**
Boidsの三原則に対応する形で、本設計では新規エージェントの典型的な**役割タイプ**をいくつか定義します。

* **Contrarian Agent（反対意見エージェント）** – *Separation（分離）戦略*: 現在の議論の多数意見とは**距離を置いた位置**に存在する意見を敢えて提示するエージェントです。全員が同意しているときにあえて異論を唱えたり、他の視点・リスク・欠点を指摘したりします。これにより議論に多様性と広がりを与え、安易な思考の収束（グループシンク）を防ぎます。【分離の原則: ボイドは近すぎる仲間から離れる】
* **Aligning Agent（同調・深化エージェント）** – *Alignment（整列）戦略*: 他のエージェントの意見の方向性に**整合**して発言するエージェントです。具体的には、有望な提案が他エージェントから出た場合にそれを補強・詳細化したり、追加の根拠を示したりして議論を前進させます。議論が発散しすぎず**収束する方向**へと寄与する役割です。【整列の原則: ボイドは近傍の群れの平均的な方向に合わせる】
* **Mediator Agent（調停・統合エージェント）** – *Cohesion（結合）戦略*: 意見が対立・分散している場合に、**折衷案**や**全体のまとめ**を提示するエージェントです。他のエージェントの発言を踏まえ、「両者の言い分にはそれぞれ一理あり、中間解として...」のように共通点を見出して統合しようとします。これにより議論全体がバラバラにならず、一定のコヒーレンス（結束）を保つようにします。【結合の原則: ボイドは仲間の重心（中心位置）へ向かおうとする】

上記以外にも、必要に応じて\*\*Explorer Agent（探索エージェント）\*\*のような役割を追加で設計可能です。例えば議論に新知識が不足して停滞している場合に、外部知識を検索して持ち込む役（RAG連携するエージェント）などが考えられます。しかし本拡張の主眼は意見の多様性と収束のバランス調整であるため、ここではContrarian/Aligning/Mediatorの3種を中心に据えます。

**エージェント生成アルゴリズム:**
`BoidsAgentFactory`は入力された`suggested_action`に応じて、生成すべきエージェントのタイプを決定します。内部的には、各タイプに対して**プロンプトテンプレート**やパラメータを用意しておき、Gemma-3 1Bモデルを用いた新エージェントインスタンスを構築します。擬似コードで表すと以下のようになります。

```python
def create_agent(action: str) -> Agent:
    if action == "add_contrarian_agent":
        role = "Contrarian"
        system_prompt = ("あなたは会議でのデビルズアドボケート（あえて反対意見を述べる役）です。他の発言者の意見に疑問を呈し、"
                         "代替案や潜在的な問題点を指摘してください。")
    elif action == "add_mediator_agent":
        role = "Mediator"
        system_prompt = ("あなたは議論の調停者です。各発言者の主張を要約し、共通点を見つけて統合案を提案してください。"
                         "対立がある場合は妥協点を示してください。")
    elif action == "add_aligning_agent":
        role = "Aligner"
        system_prompt = ("あなたは他の意見を深掘りする役割です。他の発言者の提案を支持し、それをさらに発展させる詳細な情報や理由を述べてください。")
    # ... 他の役割も必要に応じて
    new_agent = Agent(model=Gemma3_1B, role=role, system_prompt=system_prompt)
    return new_agent
```

上記のように、日本語でそれぞれの役割に応じた**システムプロンプト**（または事前プロンプト）を設定します。例えばContrarianでは「デビルズアドボケート（敢えて反論者）の人格」を与え、Mediatorでは「調停者・要約者」といった人格を与えるイメージです。このプロンプトを元にGemma-3 1Bモデルが発言を生成することで、新エージェントは期待する戦略に沿った発言傾向を示します。

エージェントを生成したら、`AgentPoolManager`に通知してプールに追加してもらいます。なお、**生成タイミング**については注意が必要です。典型的には各ラウンドの発言が終わった後に診断が行われ、新エージェントが生成されます。そして**次のラウンドから**そのエージェントが会話に参加します。このようにすれば各ラウンド内での処理順序が明確になります。一方、場合によっては診断直後の同ラウンド内で新エージェントにも発言させたいケースもあります（議論停滞を即座に打破するため、ラウンド途中参入させるなど）。実装上は多少複雑になるため、本設計では**次ラウンド参加**を基本としつつ、余裕があれば同ラウンド内追加発言も検討します。

**Boids原則への対応付け:** 上述の各エージェントタイプはBoidsの群れ行動原則と対応しています。Contrarianは既存の「群れ」（他エージェント集団）から距離を取る動きであり、Alignment役は群れの方向性に合わせる（同調する）動き、Mediatorは群れ全体がばらけすぎないよう中心へ近づける動きです。各エージェントの初期意見（初回発言内容）はその役割に沿って調整されるため、意見空間上で適切な位置に生まれるように設計されています。例えばContrarianエージェントは他と**意見ベクトル的に遠い位置**に出現し、Mediatorは他者の意見ベクトル群の**中心付近**に位置するイメージです。この調整は明示的な数値計算ではなく、**プロンプト設計とLLMの生成特性**によって実現されます。Gemma-3 1Bは指示に従って出力を変える能力があるため、適切な指示を与えることで新エージェントの振る舞いを大枠誘導できます。

**軽量・高速動作への配慮:** 新エージェント生成自体はGemma-3 1Bモデルの新規ロード等を必要とせず、既にメモリ上に読み込まれたモデルを再利用します。単に別の「人格」を与えて対話を行うだけなので、生成行為による追加のメモリコストは極小です。ただしエージェント数が増えるとその分同時にモデルを実行する回数が増えるため、AgentPoolManager側で述べるように上限管理を行います。Gemma-3 1Bは軽量とはいえ529MBありますが、これは単一インスタンスで済み（エージェントごとに複製しない）、また高いトークン生成速度で対話を妨げません。よって、新エージェントを適応的に増やす戦略はノートPC環境でも十分許容できる設計となっています。

## AgentPoolManager（エージェント統制・生存管理）

**役割:** `AgentPoolManager`はその名の通り、複数エージェントからなる**エージェントプール**を管理・統制するモジュールです。具体的には、初期エージェントの生成、各ラウンドにおけるエージェント実行順序の調整、`BoidsAgentFactory`からの新規エージェント追加やエージェント削除の実行、並びに全体のリソース制御を行います。言わば**オーケストレーター**として、他の全モジュールを適切な順序で呼び出し、システム全体が意図したサイクルで動作するよう取り仕切ります。

**主な機能:**

1. **初期エージェント配置:** ユーザから質問が入力された際、その内容に応じて最初のエージェント集団を構成します。例えば質問の種類により役割を振り分け（Q\&Aなら専門家役と解説役、ディベートなら賛成役と反対役など）、初期プールを作ります。MurmurNet既存機能である「質問分類と役割振り分け」ロジックを活用し、初期エージェントを`BoidsAgentFactory`経由で生成する形に拡張します。
2. **メイン対話ループの制御:** エージェント達による**議論ラウンドを反復**実行します。各ラウンドで行われる処理手順は次に詳述します。
3. **エージェント追加・削除:** `Self-Diagnosis`の結果に従い、新エージェントの追加（自己増殖）や不要エージェントの削除を決定し実行します。具体的には、新規生成は`BoidsAgentFactory`に委譲し、返ってきたエージェントをプールに登録します。削除は内部基準または診断結果に従いプールからエージェントインスタンスを除去し、メモリ解放やスレッド停止など後片付けを行います。
4. **実行モード（同期/非同期）管理:** 並列実行が可能な環境ではエージェントの発言生成を非同期（並列）で行いますが、トラブル時には安全のため逐次実行に切り替える必要があります。AgentPoolManagerは`--parallel`や`--safe-parallel`フラグに応じてエージェント実行のモードを制御し、例えばPythonの`asyncio`でタスクを投げて`gather`する、あるいは各エージェントを別プロセスで動かすなどの実装戦略を管理します。

**エージェント対話ループ:**
AgentPoolManager内で管理される**メインループ**は以下のような流れとなります（擬似コード形式で示します）。

```python
# 初期エージェント生成（例: 2体）
agents = initialize_agents(user_query)  # 役割振り分けしてBoidsAgentFactoryで生成
conversation_history = [user_query]

for turn in range(max_turns):
    outputs = []
    # 1. 各エージェントが順次または並列に発言生成
    for agent in agents:
        output = agent.generate(conversation_history)  # Gemma-3 1Bによる発言生成
        outputs.append((agent.id, output))
        conversation_history.append(f"{agent.name}: {output}")
    # 2. 発言をベクトル化し意見空間を更新
    for agent_id, output_text in outputs:
        vec = OpinionVectorizer.vectorize(output_text)
        OpinionSpaceManager.add_vector(agent_id, vec)
    # 3. 議論状況の自己診断
    diagnosis = SelfDiagnosis.analyze(OpinionSpaceManager.get_latest_vectors())
    # 4. 自己増殖/削除の判断と実行
    if diagnosis.suggested_action == "add_contrarian_agent":
        new_agent = BoidsAgentFactory.create_agent("add_contrarian_agent")
        agents.append(new_agent)
    if diagnosis.suggested_action == "add_mediator_agent":
        new_agent = BoidsAgentFactory.create_agent("add_mediator_agent")
        agents.append(new_agent)
    # ... 他の追加ケース
    if len(agents) > MAX_AGENTS or diagnosis.suggested_action == "remove_redundant_agent":
        remove_agent = select_removal_candidate(agents)  # 削除対象選定（後述）
        agents.remove(remove_agent)
    # 5. 終了判定: 最大ターン到達 or 十分収束 etc.
    if turn == max_turns-1 or diagnosis.is_fully_converged:
        break

# 6. 出力エージェントによる最終応答生成
final_answer = produce_final_answer(conversation_history, agents)
```

上記のフローを文章でまとめると以下の通りです。

* **(1) 並列/逐次発言生成:** 各エージェントにブラックボード上の\*\*対話履歴（conversation\_history）\*\*を入力として渡し、Gemma-3 1Bモデルで次の発言を生成させます。並列モードでは同時に生成を走らせ、全て完了するのを待ちます（各エージェントは他エージェントの今回の発言を見ずに発言する形になりますが、直前までの履歴は共有）。逐次モードでは予めエージェントの順序を決めて一体ずつ発言させ、順番が後のエージェントは前のエージェントの発言も履歴に含めてから生成します。どちらの方式でも、最終的に各ラウンドで各エージェント1発言ずつが得られます。発言結果はブラックボード（対話履歴リスト）に書き込みます。
* **(2) ベクトル化と空間更新:** 集まった全発言について、`OpinionVectorizer`でベクトル化を行い、`OpinionSpaceManager`に追加します。このときエージェントIDと紐付けて保存し、**最新意見ベクトルの集合**が更新されます。
* **(3) 自己診断:** `SelfDiagnosis.analyze()`を呼び出し、現在の意見ベクトル空間に基づく診断を実行します。診断結果（例: `suggested_action`）を受け取ります。
* **(4) エージェント追加・削除:** 診断結果に応じて`BoidsAgentFactory`で新規エージェントを生成しプールに追加します。また、プール内のエージェント数があらかじめ決められた上限（MAX\_AGENTS）を超えた場合や、診断で「冗長なエージェントがいる」と判断された場合は、何らかの基準で**削除すべきエージェント**を選び、プールから除去します。削除基準の例としては「最も古くから存在するエージェント」や「直近の貢献度が低いエージェント」などが考えられます。貢献度はSelf-Diagnosisで測れる多様性指標への寄与や、他エージェントから参照された回数などで定義できます。簡便には「直近3ターンほとんど発言内容が他と重複していたエージェント」を冗長とみなし削除する、といったルールでも良いでしょう。削除時にはエージェントに割り当てていたリソース（例えばバックグラウンドで実行中のタスクがあればキャンセルする等）を解放します。
* **(5) 継続または終了判定:** 規定の最大ターン数までループしたら終了します。あるいは診断結果が「十分議論が収束した」（例えば全エージェントの意見が一定範囲内に収まりこれ以上新しい意見が出なさそう）と判断した場合にもループを早期終了できます。またユーザから逐次対話型でなく単発質問として扱うなら1ターンで終了します。
* **(6) 最終応答生成:** 複数エージェントの議論結果を踏まえて、ユーザへの回答文を生成します。MurmurNet既存実装では`OutputAgent`（出力エージェント）がブラックボード上の内容を要約する形で最終応答を作っていました。本設計でも同様に、最終的には**回答要約エージェント**（または既存のOutputAgent）によって解答文を構成します。例えば、最後のラウンドのエージェント発言群を`conversation_history`ごとGemma-3モデルに渡し、「以上を踏まえてユーザの質問に答えてください」というプロンプトでまとめさせる手法が考えられます。あるいはMediatorエージェントが存在する場合、そのエージェントに最終回答を担当させても良いでしょう。

**モジュール間通信と非同期処理:** 上記フローにおいて、AgentPoolManagerは各ステップで適切に他モジュールを呼び出し、データを受け渡します。非同期処理を行う場合でも、基本的に**各ラウンド内の処理順序は維持**されます（発言生成だけ非同期並列し、他は逐次）。AgentPoolManagerは例えばPythonのasyncioを使って各エージェントの`agent.generate()`を同時に実行し、`await`で全完了を待ってから次のステップへ進む制御をします。並列処理中でもブラックボード上の履歴は不変（前ラウンドまでのもの）なので問題ありません。GGML等モデルバックエンドの制約で並列実行が不安定な場合は、`--safe-parallel`モードとしてエージェントごとに時間差を設けて順次実行するなど、切り替え可能にします。AgentPoolManager自体はシングルスレッドでイベントループを回し、逐次的に各処理ステップを行うため、デッドロックや競合無く動作できます。

**リソース制御戦略:**
ノートPC上で動作させるため、エージェント数や寿命に制限を設けリソースを制御します。具体的な戦略は以下の通りです。

* **最大エージェント数 (MAX\_AGENTS):** 例えば **5体** を上限とします。これによりGemma-3 1Bモデルを用いた生成を一度に5回程度に抑え、メモリ・CPU負荷を限定します（Gemma-3 1Bは小型で高速なため5並列程度は可能ですが、状況に応じ調整）。上限を超えて追加が必要な場合は、原則として新規追加前に1体削除してから追加する方針とします。
* **エージェント生存ターン:** 各エージェントには\*\*寿命（存続可能なターン数）\*\*を設定します。例えば **3ターン** 経過したエージェントは一旦退場させ、新陳代謝を図ります。これにより古いエージェントが議論を停滞させるのを防ぎます。ただし、寿命に達してもなお有用と判断される場合は延命させるなど柔軟に運用します。寿命のカウントはAgentPoolManagerで各エージェントの参加開始ターンを記録して管理します。
* **無用エージェントの削除条件:** Self-Diagnosisの結果や各エージェントの発言ログに基づき、「このエージェントはもう必要ない」と判断した場合は寿命前でも削除します。削除条件の例:

  * 他のエージェントと常に高い類似度を示し、**冗長**である（例: 毎回ほぼ同じ内容を別のエージェントと繰り返す）。
  * 発言が議論の趣旨から外れており、他から参照・発展されない（**的外れ**または**無影響**）。
  * 役割上の目的を既に果たした（例: Contrarianエージェントが一度反論を提示し議論を活性化させた後は不要になる）。
  * リソース逼迫時に消去法で選ぶ際、**最も重要度が低い**と判断される。

  AgentPoolManagerは各エージェントにスコアを付けて管理することもできます。例えば直近ターンでのユニークな情報提供度合いや他エージェントから言及された頻度などでスコアリングし、低スコアのエージェントを削除候補とします。削除時にはブラックボード上の当該エージェント発言履歴は残しますが、新たな発言生成は行わないようにします（過去の発言は議論記録として残留）。

以上により、常に適切な数のエージェントが必要十分な役割を果たし、計算資源の無駄遣いを避けるよう統制します。この制御はシステム全体を**軽量・高速**に保つ肝となります。

**コード例:** 以下はAgentPoolManagerの一部で、エージェント削除候補を選択する関数の擬似コードです。

```python
def select_removal_candidate(agents):
    # 例: 最も類似度の高い2エージェントのうち一方を削除
    max_sim = 0; pair = None
    for i,a in enumerate(agents):
        for b in agents[i+1:]:
            sim = cosine_similarity(a.last_vector, b.last_vector)
            if sim > max_sim:
                max_sim = sim; pair = (a,b)
    if max_sim > 0.9:  # 類似度高すぎなら
        # どちらか寿命長い方を削除
        return pair[0] if pair[0].age > pair[1].age else pair[1]
    # 他に削除すべきでないなら寿命最大のエージェントを削除
    return max(agents, key=lambda ag: ag.age)
```

上記は一例ですが、例えば**最も他と被っているエージェント**を削除し、そうでなければ単純に一番古いものを削除するという戦略を表しています。

**全体的な軽量・高速化:**
以上の設計により、ノートPC上でも十分動作可能なアーキテクチャとなっています。特にGemma-3 1Bモデルはモバイルでも動く高速モデルであり、複数エージェントがいてもレスポンス良く生成できます。意見ベクトル化もMiniLMによって高速に行われ、重い計算は伴いません。エージェント数やターン数を絞りつつ必要に応じて増減させることで、**知能の集団を小規模に保ちながら問題ごとに自己進化させる**というコンセプトを実現します。

各モジュールの連携により、MurmurNetは状況に応じて自ら構成を変えられる柔軟なシステムとなります。複数の小さなエージェントが協調・競合することで単一モデルでは得られない創発的な知見を引き出しつつも、適切に制御することで**暴走や収拾不能を防ぐ**設計となっています。この自己増殖拡張機構により、MurmurNetはユーザ入力に対して常に多角的に検討し、偏りなく洗練された応答を生成できる「小さくても賢い」分散型知能として進化することが期待できます。



あと、エージェントが生成されていないため原因を探る必要がある。
考えられる原因】
この状況を生む設計上のミス・バグ候補は、次のどれかです。

原因候補	詳細
① add_innovationの「診断」はするが、新エージェント生成関数が呼ばれていない	コード実装ミス。診断結果だけ残して、spawn_agent()やadd_agent()などが呼ばれてない。
② spawn_agent()を呼んでいるが、失敗している	例えば、プロンプトエラー、初期化エラーで「エージェント作成に失敗→例外握りつぶし」している。
③ spawn条件にさらに何らかの制限フィルターがある	例えば「1ターンに1体までしか増やさない」「数ターン連続停滞しないと増やさない」などの隠れルール。
④ そもそも自己増殖処理が無効化されている（オプション/フラグミス）	起動時オプションの渡し方でBoids増殖ONになっていない。

【さらに調査するべきログ／コードポイント】
次のものを探すと確定できます。

チェックするもの	何が分かるか
add_innovation後に spawn_agent関数呼び出しログが出ているか	呼ばれていれば失敗系、呼ばれてなければそもそも実装ミス
エラーログ (ERROR, WARNING) がその直後にないか	新エージェント初期化時に例外起きていないか
Boids制御部分のコード（特に if 文）	「すぐ増やす」or「複数回停滞後に増やす」などのルール