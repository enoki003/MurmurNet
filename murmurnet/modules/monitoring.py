#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹
~~~~~~~~~~~~~~~~~~~~~~~~~~~
Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±åˆã€åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ å¯è¦–åŒ–ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

ä½œè€…: Yuhi Sonoki
"""

import asyncio
import logging
import time
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
import json
import os

# Prometheusã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from prometheus_client import Counter, Histogram, Gauge, Summary, start_http_server, REGISTRY
    from prometheus_client.core import CollectorRegistry
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

# Grafana API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

@dataclass
class MetricPoint:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ"""
    timestamp: float
    value: float
    labels: Dict[str, str] = field(default_factory=dict)

@dataclass
class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±"""
    name: str
    description: str
    severity: str  # 'critical', 'warning', 'info'
    threshold: float
    comparison: str  # '>', '<', '==', '!='
    metric_name: str
    triggered: bool = False
    trigger_time: Optional[float] = None
    resolved_time: Optional[float] = None

class MetricsCollector:
    """
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨
    
    ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã€ä¿å­˜ã€é…ä¿¡
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
        self.metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        self.current_values: Dict[str, float] = {}
        
        # Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        self.prometheus_metrics: Dict[str, Any] = {}
        self.registry = CollectorRegistry() if PROMETHEUS_AVAILABLE else None
        
        # è¨­å®š
        self.collection_interval = config.get('metrics_collection_interval', 10.0)
        self.retention_hours = config.get('metrics_retention_hours', 24)
        self.enable_prometheus = config.get('enable_prometheus', True) and PROMETHEUS_AVAILABLE
        self.prometheus_port = config.get('prometheus_port', 8000)
        
        # åŒæœŸãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–
        self._lock = threading.Lock()
        self._running = False
        
        # Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
        if self.enable_prometheus:
            self._init_prometheus_metrics()
        
        self.logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨åˆæœŸåŒ–å®Œäº†")

    def _init_prometheus_metrics(self):
        """Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆæœŸåŒ–"""
        if not PROMETHEUS_AVAILABLE:
            return
        
        # åŸºæœ¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.prometheus_metrics = {
            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
            'requests_total': Counter(
                'murmurnet_requests_total',
                'Total number of requests',
                ['method', 'status'],
                registry=self.registry
            ),
            'tasks_processed_total': Counter(
                'murmurnet_tasks_processed_total',
                'Total number of tasks processed',
                ['node_id', 'task_type'],
                registry=self.registry
            ),
            'errors_total': Counter(
                'murmurnet_errors_total',
                'Total number of errors',
                ['component', 'error_type'],
                registry=self.registry
            ),
            
            # ã‚²ãƒ¼ã‚¸
            'active_nodes': Gauge(
                'murmurnet_active_nodes',
                'Number of active nodes',
                registry=self.registry
            ),
            'current_load': Gauge(
                'murmurnet_current_load',
                'Current system load',
                ['node_id'],
                registry=self.registry
            ),
            'memory_usage_bytes': Gauge(
                'murmurnet_memory_usage_bytes',
                'Memory usage in bytes',
                ['component'],
                registry=self.registry
            ),
            'pending_tasks': Gauge(
                'murmurnet_pending_tasks',
                'Number of pending tasks',
                registry=self.registry
            ),
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
            'request_duration_seconds': Histogram(
                'murmurnet_request_duration_seconds',
                'Request duration in seconds',
                ['method'],
                registry=self.registry
            ),
            'task_execution_duration_seconds': Histogram(
                'murmurnet_task_execution_duration_seconds',
                'Task execution duration in seconds',
                ['task_type'],
                registry=self.registry
            ),
            
            # ã‚µãƒãƒªãƒ¼
            'response_size_bytes': Summary(
                'murmurnet_response_size_bytes',
                'Response size in bytes',
                registry=self.registry
            )
        }
        
        self.logger.info("Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–å®Œäº†")

    async def start(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†é–‹å§‹"""
        if self._running:
            return
        
        self._running = True
        self.logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†é–‹å§‹")
        
        # Prometheusã‚µãƒ¼ãƒãƒ¼é–‹å§‹
        if self.enable_prometheus:
            try:
                start_http_server(self.prometheus_port, registry=self.registry)
                self.logger.info(f"Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒ¼ãƒãƒ¼é–‹å§‹: ãƒãƒ¼ãƒˆ {self.prometheus_port}")
            except Exception as e:
                self.logger.error(f"Prometheusã‚µãƒ¼ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰åé›†ã‚¿ã‚¹ã‚¯
        asyncio.create_task(self._collection_loop())
        asyncio.create_task(self._cleanup_loop())

    async def stop(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†åœæ­¢"""
        self._running = False
        self.logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†åœæ­¢")

    def record_metric(self, name: str, value: float, labels: Optional[Dict[str, str]] = None):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²"""
        if labels is None:
            labels = {}
        
        timestamp = time.time()
        point = MetricPoint(timestamp, value, labels)
        
        with self._lock:
            self.metrics[name].append(point)
            self.current_values[name] = value
        
        # Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚‚æ›´æ–°
        if self.enable_prometheus:
            self._update_prometheus_metric(name, value, labels)

    def _update_prometheus_metric(self, name: str, value: float, labels: Dict[str, str]):
        """Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ›´æ–°"""
        try:
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã‚’Prometheuså½¢å¼ã«ãƒãƒƒãƒ”ãƒ³ã‚°
            prometheus_name = self._map_to_prometheus_name(name)
            
            if prometheus_name in self.prometheus_metrics:
                metric = self.prometheus_metrics[prometheus_name]
                
                if hasattr(metric, 'labels'):
                    # ãƒ©ãƒ™ãƒ«ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹
                    labeled_metric = metric.labels(**labels)
                    if hasattr(labeled_metric, 'set'):
                        labeled_metric.set(value)
                    elif hasattr(labeled_metric, 'inc'):
                        labeled_metric.inc(value)
                else:
                    # ãƒ©ãƒ™ãƒ«ãªã—ãƒ¡ãƒˆãƒªã‚¯ã‚¹
                    if hasattr(metric, 'set'):
                        metric.set(value)
                    elif hasattr(metric, 'inc'):
                        metric.inc(value)
                        
        except Exception as e:
            self.logger.debug(f"Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def _map_to_prometheus_name(self, name: str) -> str:
        """å†…éƒ¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹åã‚’Prometheusåã«ãƒãƒƒãƒ”ãƒ³ã‚°"""
        mapping = {
            'active_nodes_count': 'active_nodes',
            'node_load': 'current_load',
            'memory_usage': 'memory_usage_bytes',
            'pending_tasks_count': 'pending_tasks',
            'requests_count': 'requests_total',
            'tasks_processed_count': 'tasks_processed_total',
            'errors_count': 'errors_total',
            'request_duration': 'request_duration_seconds',
            'task_duration': 'task_execution_duration_seconds',
            'response_size': 'response_size_bytes'
        }
        return mapping.get(name, name)

    def get_metric_history(self, name: str, hours: int = 1) -> List[MetricPoint]:
        """æŒ‡å®šæ™‚é–“å†…ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã‚’å–å¾—"""
        cutoff_time = time.time() - (hours * 3600)
        
        with self._lock:
            if name not in self.metrics:
                return []
            
            return [
                point for point in self.metrics[name]
                if point.timestamp >= cutoff_time
            ]

    def get_current_value(self, name: str) -> Optional[float]:
        """ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å€¤ã‚’å–å¾—"""
        return self.current_values.get(name)

    def get_aggregated_metrics(self, hours: int = 1) -> Dict[str, Dict[str, float]]:
        """é›†ç´„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        result = {}
        
        for name in self.metrics.keys():
            history = self.get_metric_history(name, hours)
            if not history:
                continue
            
            values = [point.value for point in history]
            result[name] = {
                'min': min(values),
                'max': max(values),
                'avg': sum(values) / len(values),
                'current': values[-1] if values else 0,
                'count': len(values)
            }
        
        return result

    async def _collection_loop(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ«ãƒ¼ãƒ—"""
        while self._running:
            try:
                await self._collect_system_metrics()
                await asyncio.sleep(self.collection_interval)
            except Exception as e:
                self.logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")

    async def _collect_system_metrics(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        try:
            import psutil
            
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent()
            self.record_metric('cpu_usage_percent', cpu_percent)
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            self.record_metric('memory_usage_percent', memory.percent)
            self.record_metric('memory_usage', memory.used, {'component': 'system'})
            
            # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            self.record_metric('disk_usage_percent', disk_percent)
            
        except ImportError:
            # psutilãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯åŸºæœ¬çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿
            pass
        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")

    async def _cleanup_loop(self):
        """å¤ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        while self._running:
            try:
                cutoff_time = time.time() - (self.retention_hours * 3600)
                
                with self._lock:
                    for name, points in self.metrics.items():
                        # å¤ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
                        while points and points[0].timestamp < cutoff_time:
                            points.popleft()
                
                # 1æ™‚é–“ã”ã¨ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                await asyncio.sleep(3600)
                
            except Exception as e:
                self.logger.error(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

class AlertManager:
    """
    ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    
    ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ãƒ¼ãƒˆç™ºå ±ãƒ»ç®¡ç†
    """
    
    def __init__(self, config: Dict[str, Any], metrics_collector: MetricsCollector):
        self.config = config
        self.metrics_collector = metrics_collector
        self.logger = logging.getLogger(__name__)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alerts: Dict[str, Alert] = {}
        self.alert_handlers: List[Callable] = []
        self.check_interval = config.get('alert_check_interval', 30.0)
        
        # é€šçŸ¥è¨­å®š
        self.notification_channels = config.get('notification_channels', [])
        
        self._running = False
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¨­å®š
        self._setup_default_alerts()
        
        self.logger.info("ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    def _setup_default_alerts(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¨­å®š"""
        default_alerts = [
            Alert(
                name='high_cpu_usage',
                description='CPUä½¿ç”¨ç‡ãŒé«˜ã„',
                severity='warning',
                threshold=80.0,
                comparison='>',
                metric_name='cpu_usage_percent'
            ),
            Alert(
                name='high_memory_usage',
                description='ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„',
                severity='warning',
                threshold=85.0,
                comparison='>',
                metric_name='memory_usage_percent'
            ),
            Alert(
                name='no_active_nodes',
                description='ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒãƒ¼ãƒ‰ãŒãªã„',
                severity='critical',
                threshold=1.0,
                comparison='<',
                metric_name='active_nodes_count'
            ),
            Alert(
                name='high_error_rate',
                description='ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„',
                severity='critical',
                threshold=10.0,
                comparison='>',
                metric_name='error_rate_percent'
            )
        ]
        
        for alert in default_alerts:
            self.alerts[alert.name] = alert

    async def start(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†é–‹å§‹"""
        if self._running:
            return
        
        self._running = True
        self.logger.info("ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†é–‹å§‹")
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
        asyncio.create_task(self._alert_check_loop())

    async def stop(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†åœæ­¢"""
        self._running = False
        self.logger.info("ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†åœæ­¢")

    def add_alert(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¿½åŠ """
        self.alerts[alert.name] = alert
        self.logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆè¿½åŠ : {alert.name}")

    def remove_alert(self, name: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å‰Šé™¤"""
        if name in self.alerts:
            del self.alerts[name]
            self.logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆå‰Šé™¤: {name}")

    def add_alert_handler(self, handler: Callable):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¿½åŠ """
        self.alert_handlers.append(handler)

    async def _alert_check_loop(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ—"""
        while self._running:
            try:
                await self._check_alerts()
                await asyncio.sleep(self.check_interval)
            except Exception as e:
                self.logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

    async def _check_alerts(self):
        """ã™ã¹ã¦ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        for alert in self.alerts.values():
            try:
                await self._check_single_alert(alert)
            except Exception as e:
                self.logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆ {alert.name} ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

    async def _check_single_alert(self, alert: Alert):
        """å˜ä¸€ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯"""
        current_value = self.metrics_collector.get_current_value(alert.metric_name)
        
        if current_value is None:
            return
        
        # ã—ãã„å€¤ã¨æ¯”è¼ƒ
        triggered = self._evaluate_condition(current_value, alert.threshold, alert.comparison)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ…‹ã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
        if triggered and not alert.triggered:
            # ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç«
            alert.triggered = True
            alert.trigger_time = time.time()
            await self._fire_alert(alert, current_value)
            
        elif not triggered and alert.triggered:
            # ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±º
            alert.triggered = False
            alert.resolved_time = time.time()
            await self._resolve_alert(alert, current_value)

    def _evaluate_condition(self, value: float, threshold: float, comparison: str) -> bool:
        """æ¡ä»¶ã‚’è©•ä¾¡"""
        if comparison == '>':
            return value > threshold
        elif comparison == '<':
            return value < threshold
        elif comparison == '==':
            return abs(value - threshold) < 0.001
        elif comparison == '!=':
            return abs(value - threshold) >= 0.001
        return False

    async def _fire_alert(self, alert: Alert, current_value: float):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ç™ºç«"""
        self.logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç«: {alert.name} - {alert.description}")
        
        alert_data = {
            'name': alert.name,
            'description': alert.description,
            'severity': alert.severity,
            'current_value': current_value,
            'threshold': alert.threshold,
            'trigger_time': alert.trigger_time,
            'status': 'fired'
        }
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å®Ÿè¡Œ
        for handler in self.alert_handlers:
            try:
                await handler(alert_data)
            except Exception as e:
                self.logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        
        # é€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«ã«é€ä¿¡
        await self._send_notifications(alert_data)

    async def _resolve_alert(self, alert: Alert, current_value: float):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è§£æ±º"""
        self.logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±º: {alert.name}")
        
        alert_data = {
            'name': alert.name,
            'description': alert.description,
            'severity': alert.severity,
            'current_value': current_value,
            'threshold': alert.threshold,
            'resolved_time': alert.resolved_time,
            'status': 'resolved'
        }
        
        # é€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«ã«é€ä¿¡
        await self._send_notifications(alert_data)

    async def _send_notifications(self, alert_data: Dict[str, Any]):
        """é€šçŸ¥ã‚’é€ä¿¡"""
        for channel in self.notification_channels:
            try:
                if channel['type'] == 'webhook':
                    await self._send_webhook_notification(channel, alert_data)
                elif channel['type'] == 'slack':
                    await self._send_slack_notification(channel, alert_data)
                elif channel['type'] == 'email':
                    await self._send_email_notification(channel, alert_data)
            except Exception as e:
                self.logger.error(f"é€šçŸ¥é€ä¿¡ã‚¨ãƒ©ãƒ¼ ({channel['type']}): {e}")

    async def _send_webhook_notification(self, channel: Dict[str, Any], alert_data: Dict[str, Any]):
        """Webhooké€šçŸ¥ã‚’é€ä¿¡"""
        if not REQUESTS_AVAILABLE:
            return
        
        url = channel.get('url')
        if not url:
            return
        
        payload = {
            'alert': alert_data,
            'timestamp': time.time()
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            response.raise_for_status()
        except Exception as e:
            self.logger.error(f"Webhooké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    async def _send_slack_notification(self, channel: Dict[str, Any], alert_data: Dict[str, Any]):
        """Slacké€šçŸ¥ã‚’é€ä¿¡"""
        # Slack Webhookå®Ÿè£…
        webhook_url = channel.get('webhook_url')
        if not webhook_url or not REQUESTS_AVAILABLE:
            return
        
        color = 'danger' if alert_data['severity'] == 'critical' else 'warning'
        status_emoji = 'ğŸ”¥' if alert_data['status'] == 'fired' else 'âœ…'
        
        payload = {
            'attachments': [{
                'color': color,
                'title': f"{status_emoji} {alert_data['name']}",
                'text': alert_data['description'],
                'fields': [
                    {
                        'title': 'Current Value',
                        'value': str(alert_data['current_value']),
                        'short': True
                    },
                    {
                        'title': 'Threshold',
                        'value': str(alert_data['threshold']),
                        'short': True
                    }
                ],
                'timestamp': int(time.time())
            }]
        }
        
        try:
            response = requests.post(webhook_url, json=payload, timeout=10)
            response.raise_for_status()
        except Exception as e:
            self.logger.error(f"Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    async def _send_email_notification(self, channel: Dict[str, Any], alert_data: Dict[str, Any]):
        """Emailé€šçŸ¥ã‚’é€ä¿¡"""
        # ç°¡å˜ãªEmailå®Ÿè£…ï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã‚ˆã‚Šå …ç‰¢ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
        self.logger.info(f"Emailé€šçŸ¥ï¼ˆæœªå®Ÿè£…ï¼‰: {alert_data['name']}")

    def get_alert_status(self) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆçŠ¶æ…‹ã‚’å–å¾—"""
        active_alerts = [
            {
                'name': alert.name,
                'description': alert.description,
                'severity': alert.severity,
                'triggered': alert.triggered,
                'trigger_time': alert.trigger_time
            }
            for alert in self.alerts.values()
            if alert.triggered
        ]
        
        return {
            'total_alerts': len(self.alerts),
            'active_alerts': len(active_alerts),
            'alerts': active_alerts
        }

class DashboardManager:
    """
    ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
    
    Grafanaç­‰ã®å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¨ã®çµ±åˆ
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # Grafanaè¨­å®š
        self.grafana_url = config.get('grafana_url')
        self.grafana_api_key = config.get('grafana_api_key')
        
        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
        self.dashboard_config = {
            'title': 'MurmurNet åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–',
            'tags': ['murmurnet', 'distributed'],
            'refresh': '30s',
            'time': {
                'from': 'now-1h',
                'to': 'now'
            }
        }
        
        self.logger.info("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    async def create_dashboard(self) -> bool:
        """Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆ"""
        if not self.grafana_url or not self.grafana_api_key or not REQUESTS_AVAILABLE:
            self.logger.warning("Grafanaè¨­å®šãŒä¸å®Œå…¨ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return False
        
        try:
            dashboard_json = self._generate_dashboard_json()
            
            headers = {
                'Authorization': f'Bearer {self.grafana_api_key}',
                'Content-Type': 'application/json'
            }
            
            response = requests.post(
                f'{self.grafana_url}/api/dashboards/db',
                json=dashboard_json,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                self.logger.info("Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆæˆåŠŸ")
                return True
            else:
                self.logger.error(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            self.logger.error(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆä¾‹å¤–: {e}")
            return False

    def _generate_dashboard_json(self) -> Dict[str, Any]:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰JSONå®šç¾©ã‚’ç”Ÿæˆ"""
        return {
            'dashboard': {
                'title': self.dashboard_config['title'],
                'tags': self.dashboard_config['tags'],
                'refresh': self.dashboard_config['refresh'],
                'time': self.dashboard_config['time'],
                'panels': [
                    self._create_system_overview_panel(),
                    self._create_node_status_panel(),
                    self._create_task_metrics_panel(),
                    self._create_performance_panel(),
                    self._create_alert_panel()
                ]
            },
            'overwrite': True
        }

    def _create_system_overview_panel(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦ãƒ‘ãƒãƒ«"""
        return {
            'title': 'ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦',
            'type': 'stat',
            'targets': [
                {
                    'expr': 'murmurnet_active_nodes',
                    'legendFormat': 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ¼ãƒ‰'
                },
                {
                    'expr': 'murmurnet_pending_tasks',
                    'legendFormat': 'å¾…æ©Ÿã‚¿ã‚¹ã‚¯'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 0, 'y': 0}
        }

    def _create_node_status_panel(self) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒ‰çŠ¶æ…‹ãƒ‘ãƒãƒ«"""
        return {
            'title': 'ãƒãƒ¼ãƒ‰è² è·',
            'type': 'graph',
            'targets': [
                {
                    'expr': 'murmurnet_current_load',
                    'legendFormat': 'ãƒãƒ¼ãƒ‰ {{node_id}}'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 12, 'y': 0}
        }

    def _create_task_metrics_panel(self) -> Dict[str, Any]:
        """ã‚¿ã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‘ãƒãƒ«"""
        return {
            'title': 'ã‚¿ã‚¹ã‚¯å‡¦ç†çŠ¶æ³',
            'type': 'graph',
            'targets': [
                {
                    'expr': 'rate(murmurnet_tasks_processed_total[5m])',
                    'legendFormat': 'å‡¦ç†ãƒ¬ãƒ¼ãƒˆ'
                },
                {
                    'expr': 'rate(murmurnet_errors_total[5m])',
                    'legendFormat': 'ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ¼ãƒˆ'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 0, 'y': 8}
        }

    def _create_performance_panel(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ãƒãƒ«"""
        return {
            'title': 'ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“',
            'type': 'graph',
            'targets': [
                {
                    'expr': 'histogram_quantile(0.95, murmurnet_request_duration_seconds_bucket)',
                    'legendFormat': '95%ile'
                },
                {
                    'expr': 'histogram_quantile(0.50, murmurnet_request_duration_seconds_bucket)',
                    'legendFormat': '50%ile'
                }
            ],
            'gridPos': {'h': 8, 'w': 12, 'x': 12, 'y': 8}
        }

    def _create_alert_panel(self) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ‘ãƒãƒ«"""
        return {
            'title': 'ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ',
            'type': 'table',
            'targets': [
                {
                    'expr': 'ALERTS{alertstate="firing"}',
                    'format': 'table'
                }
            ],
            'gridPos': {'h': 8, 'w': 24, 'x': 0, 'y': 16}
        }

def create_metrics_collector(config: Dict[str, Any]) -> MetricsCollector:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨ã‚’ä½œæˆ"""
    return MetricsCollector(config)

def create_alert_manager(config: Dict[str, Any], metrics_collector: MetricsCollector) -> AlertManager:
    """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ"""
    return AlertManager(config, metrics_collector)

def create_dashboard_manager(config: Dict[str, Any]) -> DashboardManager:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆ"""
    return DashboardManager(config)
