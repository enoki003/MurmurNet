#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
MurmurNet åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
åˆ†æ•£å‰µç™ºå‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®å…¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
- åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
- ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
- RAGæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆï¼ˆZIM/Embeddingï¼‰
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
- è¨­å®šç®¡ç†ãƒ†ã‚¹ãƒˆ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ
- ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ

ä½œè€…: Yuhi Sonoki (Updated by GitHub Copilot)
"""

import sys
import os
import logging
import asyncio
import time
import gc
import traceback
import psutil
from typing import Dict, Any, List, Optional, Tuple
import unittest
from unittest.mock import patch, MagicMock
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.FileHandler("comprehensive_test_log.txt", mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¨­å®š
project_root = Path(__file__).resolve().parent.parent
sys.path.append(str(project_root))

# MurmurNetãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from MurmurNet.distributed_slm import DistributedSLM
from MurmurNet.modules.blackboard import Blackboard
from MurmurNet.modules.input_reception import InputReception
from MurmurNet.modules.agent_pool import AgentPoolManager
from MurmurNet.modules.rag_retriever import RAGRetriever
from MurmurNet.modules.output_agent import OutputAgent
from MurmurNet.modules.summary_engine import SummaryEngine
from MurmurNet.modules.conversation_memory import ConversationMemory
from MurmurNet.modules.config_manager import ConfigManager, get_config
from MurmurNet.modules.model_factory import get_shared_model
from MurmurNet.modules.system_coordinator import SystemCoordinator
from MurmurNet.modules.performance import PerformanceMonitor
from MurmurNet.modules.common import MurmurNetError

# ãƒ†ã‚¹ãƒˆè¨­å®š
MODELS_PATH = r"C:\Users\admin\Desktop\èª²é¡Œç ”ç©¶\models"
ZIM_PATH = r"C:\Users\admin\Desktop\èª²é¡Œç ”ç©¶\KNOWAGE_DATABASE\wikipedia_en_top_nopic_2025-03.zim"

# åŸºæœ¬è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
BASE_CONFIG = {
    "num_agents": 2,
    "iterations": 1,
    "use_summary": True,
    "use_parallel": False,
    "model_type": "gemma3",
    "rag_mode": "zim",
    "rag_score_threshold": 0.5,
    "rag_top_k": 3,
    "debug": True,
    "model_path": os.path.join(MODELS_PATH, "gemma-3-1b-it-q4_0.gguf"),
    "chat_template": os.path.join(MODELS_PATH, "gemma3_template.txt"),
    "zim_path": ZIM_PATH,
    "n_threads": 4,
    "n_ctx": 2048,
}

DEFAULT_CONFIG = BASE_CONFIG.copy()

# ãƒ†ã‚¹ãƒˆçµæœè¨˜éŒ²
test_results = {
    "passed": [],
    "failed": [],
    "skipped": [],
    "total_time": 0,
    "memory_usage": {},
    "performance_metrics": {}
}

def print_header(title: str, level: int = 1) -> None:
    """ãƒ†ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ˜ãƒƒãƒ€ãƒ¼å‡ºåŠ›"""
    char = "=" if level == 1 else "-" if level == 2 else "Â·"
    width = 60 if level == 1 else 50 if level == 2 else 40
    print(f"\n{char * width}")
    print(f"{title}")
    print(f"{char * width}")

def print_result(test_name: str, success: bool, message: str, duration: float = 0) -> None:
    """ãƒ†ã‚¹ãƒˆçµæœã®å‡ºåŠ›ã¨è¨˜éŒ²"""
    status = "âœ“ PASS" if success else "âœ— FAIL"
    duration_str = f" ({duration:.2f}s)" if duration > 0 else ""
    print(f"{status} {test_name}{duration_str}")
    if message:
        print(f"    {message}")
    
    # çµæœã‚’è¨˜éŒ²
    result_entry = {
        "name": test_name,
        "message": message,
        "duration": duration,
        "timestamp": time.time()
    }
    
    if success:
        test_results["passed"].append(result_entry)
    else:
        test_results["failed"].append(result_entry)

def measure_memory() -> Dict[str, float]:
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸¬å®š"""
    process = psutil.Process()
    memory_info = process.memory_info()
    return {
        "rss": memory_info.rss / 1024 / 1024,  # MB
        "vms": memory_info.vms / 1024 / 1024,  # MB
        "percent": process.memory_percent()
    }

class ComprehensiveTestSuite:
    """åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.start_time = time.time()
        self.initial_memory = measure_memory()
        self.slm_instances = {}
        
    async def run_all_tests(self):
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print_header("MurmurNet åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆé–‹å§‹")
        print(f"é–‹å§‹æ™‚åˆ»: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: RSS={self.initial_memory['rss']:.1f}MB, VMS={self.initial_memory['vms']:.1f}MB")
        
        try:
            # 1. åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            await self.test_basic_functionality()
            
            # 2. è¨­å®šç®¡ç†ãƒ†ã‚¹ãƒˆ
            await self.test_configuration_management()
            
            # 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ
            await self.test_module_integration()
            
            # 4. RAGæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            await self.test_rag_functionality()
            
            # 5. ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
            await self.test_parallel_processing()
            
            # 6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
            await self.test_error_handling()
            
            # 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
            await self.test_performance()
            
            # 8. ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ
            await self.test_memory_management()
            
            # 9. ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
            await self.test_end_to_end()
            
        except Exception as e:
            print_result("ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ", False, f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
        
        finally:
            await self.cleanup_and_report()
    
    async def test_basic_functionality(self):
        """åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print_header("åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. Blackboardãƒ†ã‚¹ãƒˆ
        await self._test_blackboard()
        
        # 2. InputReceptionãƒ†ã‚¹ãƒˆ
        await self._test_input_reception()
        
        # 3. OutputAgentãƒ†ã‚¹ãƒˆ
        await self._test_output_agent()
        
        # 4. ConversationMemoryãƒ†ã‚¹ãƒˆ
        await self._test_conversation_memory()
    
    async def _test_blackboard(self):
        """Blackboardã®åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            blackboard = Blackboard(config)
            
            # æ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ
            entry = blackboard.write("test_key", "test_value")
            assert entry["key"] == "test_key"
            assert entry["value"] == "test_value"
            
            # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
            value = blackboard.read("test_key")
            assert value == "test_value"
            
            # å±¥æ­´ãƒ†ã‚¹ãƒˆ
            history = blackboard.get_history("test_key")
            assert len(history) == 1
            
            # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãƒ†ã‚¹ãƒˆ
            memory = blackboard.memory
            assert isinstance(memory, dict)
            assert "test_key" in memory
            
            duration = time.time() - start_time
            print_result("BlackboardåŸºæœ¬æ©Ÿèƒ½", True, "æ›¸ãè¾¼ã¿ã€èª­ã¿è¾¼ã¿ã€å±¥æ­´ã€ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹æ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("BlackboardåŸºæœ¬æ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_input_reception(self):
        """InputReceptionã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            blackboard = Blackboard(config)
            input_reception = InputReception(config, blackboard)
            
            # åŸºæœ¬çš„ãªå…¥åŠ›å‡¦ç†
            test_input = "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆå…¥åŠ›ã§ã™ã€‚"
            processed = input_reception.process(test_input)
            
            assert processed is not None
            assert len(str(processed)) > 0
            
            duration = time.time() - start_time
            print_result("InputReceptionæ©Ÿèƒ½", True, "å…¥åŠ›å‡¦ç†æ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("InputReceptionæ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_output_agent(self):
        """OutputAgentã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            blackboard = Blackboard(config)
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’é»’æ¿ã«è¨­å®š
            blackboard.write("agent_0_output", "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ0ã®å¿œç­”ã§ã™ã€‚")
            blackboard.write("agent_1_output", "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1ã®å¿œç­”ã§ã™ã€‚")
            
            output_agent = OutputAgent(config, blackboard)
            final_response = await output_agent.generate_final_response()
            
            assert final_response is not None
            assert len(final_response) > 0
            
            duration = time.time() - start_time
            print_result("OutputAgentæ©Ÿèƒ½", True, "æœ€çµ‚å¿œç­”ç”Ÿæˆæ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("OutputAgentæ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_conversation_memory(self):
        """ConversationMemoryã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            conv_memory = ConversationMemory(config)
            
            # ä¼šè©±è¿½åŠ ãƒ†ã‚¹ãƒˆ
            conv_memory.add_conversation("ãƒ¦ãƒ¼ã‚¶ãƒ¼", "ã“ã‚“ã«ã¡ã¯")
            conv_memory.add_conversation("AI", "ã“ã‚“ã«ã¡ã¯ï¼")
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ
            context = conv_memory.get_context(max_length=100)
            assert len(context) > 0
            assert "ã“ã‚“ã«ã¡ã¯" in context
            
            # è¦ç´„ãƒ†ã‚¹ãƒˆ
            summary = conv_memory.get_summary()
            assert summary is not None
            
            duration = time.time() - start_time
            print_result("ConversationMemoryæ©Ÿèƒ½", True, "ä¼šè©±è¨˜æ†¶æ©Ÿèƒ½æ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ConversationMemoryæ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_configuration_management(self):
        """è¨­å®šç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        print_header("è¨­å®šç®¡ç†ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. ConfigManagerãƒ†ã‚¹ãƒˆ
        await self._test_config_manager()
        
        # 2. è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
        await self._test_config_validation()
    
    async def _test_config_manager(self):
        """ConfigManagerã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹è¨­å®š
            config_manager = ConfigManager()
            assert config_manager is not None
            
            # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
            model_type = config_manager.model_type
            assert model_type in ["gemma3", "llama", "local"]
            
            rag_mode = config_manager.rag_mode
            assert rag_mode in ["zim", "embedding"]
            
            # è¾æ›¸ãƒ™ãƒ¼ã‚¹è¨­å®š
            test_config = {"model_type": "gemma3", "rag_mode": "zim"}
            config_manager_dict = ConfigManager(test_config)
            assert config_manager_dict.model_type == "gemma3"
            
            duration = time.time() - start_time
            print_result("ConfigManageræ©Ÿèƒ½", True, "è¨­å®šèª­ã¿è¾¼ã¿ãƒ»ã‚¢ã‚¯ã‚»ã‚¹æ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ConfigManageræ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_config_validation(self):
        """è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            # æœ‰åŠ¹ãªè¨­å®š
            valid_config = BASE_CONFIG.copy()
            config_manager = ConfigManager(valid_config)
            assert config_manager is not None
            
            # ç„¡åŠ¹ãªè¨­å®šï¼ˆå­˜åœ¨ã—ãªã„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼‰
            try:
                invalid_config = BASE_CONFIG.copy()
                invalid_config["model_type"] = "invalid_model"
                ConfigManager(invalid_config)
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„å ´åˆã¯å•é¡Œ
                raise AssertionError("ç„¡åŠ¹ãªè¨­å®šãŒå—ã‘å…¥ã‚Œã‚‰ã‚ŒãŸ")
            except Exception:
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒæœŸå¾…ã•ã‚Œã‚‹
                pass
            
            duration = time.time() - start_time
            print_result("è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³", True, "æœ‰åŠ¹ãƒ»ç„¡åŠ¹è¨­å®šã®åˆ¤å®šæ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_module_integration(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print_header("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. DistributedSLMåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
        await self._test_distributed_slm_init()
        
        # 2. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€šä¿¡ãƒ†ã‚¹ãƒˆ
        await self._test_module_communication()
    
    async def _test_distributed_slm_init(self):
        """DistributedSLMåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            slm = DistributedSLM(config)
            
            # åŸºæœ¬å±æ€§ç¢ºèª
            assert slm.num_agents == config["num_agents"]
            assert slm.iterations == config["iterations"]
            assert slm.use_summary == config["use_summary"]
            
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–ç¢ºèª
            assert hasattr(slm, 'blackboard')
            assert hasattr(slm, 'input_reception')
            assert hasattr(slm, 'agent_pool')
            assert hasattr(slm, 'output_agent')
            
            duration = time.time() - start_time
            print_result("DistributedSLMåˆæœŸåŒ–", True, "å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ­£å¸¸åˆæœŸåŒ–", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("DistributedSLMåˆæœŸåŒ–", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_module_communication(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€šä¿¡ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["num_agents"] = 1  # é«˜é€ŸåŒ–ã®ãŸã‚
            slm = DistributedSLM(config)
            
            # ç°¡å˜ãªè³ªå•ã§é€šä¿¡ãƒ†ã‚¹ãƒˆ
            test_question = "ãƒ†ã‚¹ãƒˆã§ã™"
            response = await slm.generate(test_question)
            
            assert response is not None
            assert len(response) > 0
            assert isinstance(response, str)
            
            duration = time.time() - start_time
            print_result("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€šä¿¡", True, "ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰é€šä¿¡æ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€šä¿¡", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_rag_functionality(self):
        """RAGæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print_header("RAGæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. ZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        await self._test_zim_mode()
        
        # 2. Embeddingãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        await self._test_embedding_mode()
    
    async def _test_zim_mode(self):
        """ZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["rag_mode"] = "zim"
            config["zim_path"] = ZIM_PATH
            
            # ZIMãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(ZIM_PATH):
                print_result("ZIMãƒ¢ãƒ¼ãƒ‰", False, f"ZIMãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ZIM_PATH}", 0)
                return
            
            blackboard = Blackboard(config)
            rag_retriever = RAGRetriever(config, blackboard)
            
            # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            query = "artificial intelligence"
            rag_result = rag_retriever.retrieve(query)
            
            assert rag_result is not None
            assert len(rag_result) > 0
            
            duration = time.time() - start_time
            print_result("ZIMãƒ¢ãƒ¼ãƒ‰", True, "ZIMæ¤œç´¢æ­£å¸¸å‹•ä½œ", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ZIMãƒ¢ãƒ¼ãƒ‰", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_embedding_mode(self):
        """Embeddingãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["rag_mode"] = "embedding"
            
            blackboard = Blackboard(config)
            rag_retriever = RAGRetriever(config, blackboard)
            
            # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            query = "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦"
            rag_result = rag_retriever.retrieve(query)
            
            assert rag_result is not None
            
            duration = time.time() - start_time
            print_result("Embeddingãƒ¢ãƒ¼ãƒ‰", True, "åŸ‹ã‚è¾¼ã¿æ¤œç´¢æ­£å¸¸å‹•ä½œ", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("Embeddingãƒ¢ãƒ¼ãƒ‰", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_parallel_processing(self):
        """ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        print_header("ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. ä¸¦åˆ—å‡¦ç†è¨­å®šãƒ†ã‚¹ãƒˆ
        await self._test_parallel_configuration()
        
        # 2. ä¸¦åˆ— vs é€æ¬¡æ€§èƒ½æ¯”è¼ƒ
        await self._test_parallel_vs_sequential()
    
    async def _test_parallel_configuration(self):
        """ä¸¦åˆ—å‡¦ç†è¨­å®šãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["use_parallel"] = True
            config["num_agents"] = 2
            
            slm = DistributedSLM(config)
            
            # ä¸¦åˆ—è¨­å®šç¢ºèª
            assert slm.use_parallel == True
            
            # SystemCoordinatorç¢ºèª
            if hasattr(slm, 'system_coordinator'):
                coordinator = slm.system_coordinator
                assert coordinator.use_parallel == True
            
            duration = time.time() - start_time
            print_result("ä¸¦åˆ—å‡¦ç†è¨­å®š", True, "ä¸¦åˆ—å‡¦ç†è¨­å®šæ­£å¸¸", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ä¸¦åˆ—å‡¦ç†è¨­å®š", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_parallel_vs_sequential(self):
        """ä¸¦åˆ— vs é€æ¬¡æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            base_config = BASE_CONFIG.copy()
            base_config["num_agents"] = 2
            base_config["iterations"] = 1
            base_config["use_summary"] = False  # é«˜é€ŸåŒ–
            
            test_query = "ç°¡å˜ãªãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª"
            
            # é€æ¬¡å‡¦ç†
            seq_config = base_config.copy()
            seq_config["use_parallel"] = False
            slm_seq = DistributedSLM(seq_config)
            
            seq_start = time.time()
            response_seq = await slm_seq.generate(test_query)
            seq_time = time.time() - seq_start
            
            # ä¸¦åˆ—å‡¦ç†
            par_config = base_config.copy()
            par_config["use_parallel"] = True
            slm_par = DistributedSLM(par_config)
            
            par_start = time.time()
            response_par = await slm_par.generate(test_query)
            par_time = time.time() - par_start
            
            # çµæœç¢ºèª
            assert response_seq is not None
            assert response_par is not None
            
            speedup = seq_time / par_time if par_time > 0 else 1.0
            
            duration = time.time() - start_time
            message = f"é€æ¬¡: {seq_time:.2f}s, ä¸¦åˆ—: {par_time:.2f}s, é€Ÿåº¦å‘ä¸Š: {speedup:.2f}x"
            print_result("ä¸¦åˆ—vsé€æ¬¡æ€§èƒ½", True, message, duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ä¸¦åˆ—vsé€æ¬¡æ€§èƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        print_header("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. ä¸æ­£ãªè¨­å®šãƒ†ã‚¹ãƒˆ
        await self._test_invalid_configuration()
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ãƒ†ã‚¹ãƒˆ
        await self._test_missing_files()
        
        # 3. ä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ
        await self._test_exception_handling()
    
    async def _test_invalid_configuration(self):
        """ä¸æ­£ãªè¨­å®šã§ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            # ä¸æ­£ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°
            invalid_config = BASE_CONFIG.copy()
            invalid_config["num_agents"] = -1
            
            try:
                slm = DistributedSLM(invalid_config)
                raise AssertionError("ä¸æ­£ãªè¨­å®šãŒå—ã‘å…¥ã‚Œã‚‰ã‚ŒãŸ")
            except Exception:
                pass  # æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼
            
            duration = time.time() - start_time
            print_result("ä¸æ­£è¨­å®šãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", True, "ä¸æ­£è¨­å®šã‚’é©åˆ‡ã«æ‹’å¦", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ä¸æ­£è¨­å®šãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_missing_files(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["model_path"] = "non_existent_model.gguf"
            
            try:
                slm = DistributedSLM(config)
                # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã¯ãš
                await slm.generate("test")
                raise AssertionError("å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒå—ã‘å…¥ã‚Œã‚‰ã‚ŒãŸ")
            except Exception:
                pass  # æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼
            
            duration = time.time() - start_time
            print_result("ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", True, "ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ã‚’é©åˆ‡ã«æ¤œå‡º", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_exception_handling(self):
        """ä¸€èˆ¬çš„ãªä¾‹å¤–å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            slm = DistributedSLM(config)
            
            # ç©ºã®å…¥åŠ›ã§ã®ãƒ†ã‚¹ãƒˆ
            response = await slm.generate("")
            assert response is not None  # ç©ºã§ã‚‚ä½•ã‚‰ã‹ã®å¿œç­”ãŒã‚ã‚‹ã¹ã
            
            # éå¸¸ã«é•·ã„å…¥åŠ›ã§ã®ãƒ†ã‚¹ãƒˆ
            long_input = "test " * 1000
            response = await slm.generate(long_input)
            assert response is not None
            
            duration = time.time() - start_time
            print_result("ä¾‹å¤–å‡¦ç†", True, "ç•°å¸¸å…¥åŠ›ã‚’é©åˆ‡ã«å‡¦ç†", duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ä¾‹å¤–å‡¦ç†", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_performance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print_header("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. å¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆ
        await self._test_response_time()
        
        # 2. ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
        await self._test_throughput()
        
        # 3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ
        await self._test_memory_efficiency()
    
    async def _test_response_time(self):
        """å¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["num_agents"] = 1  # é«˜é€ŸåŒ–
            slm = DistributedSLM(config)
            
            queries = [
                "ã“ã‚“ã«ã¡ã¯",
                "äººå·¥çŸ¥èƒ½ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
                "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„"
            ]
            
            total_time = 0
            for query in queries:
                query_start = time.time()
                response = await slm.generate(query)
                query_time = time.time() - query_start
                total_time += query_time
                
                assert response is not None
                assert len(response) > 0
            
            avg_time = total_time / len(queries)
            
            duration = time.time() - start_time
            message = f"å¹³å‡å¿œç­”æ™‚é–“: {avg_time:.2f}s ({len(queries)}ã‚¯ã‚¨ãƒª)"
            print_result("å¿œç­”æ™‚é–“", True, message, duration)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
            test_results["performance_metrics"]["avg_response_time"] = avg_time
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("å¿œç­”æ™‚é–“", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_throughput(self):
        """ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["use_parallel"] = True
            config["num_agents"] = 2
            slm = DistributedSLM(config)
            
            num_requests = 3  # è»½é‡ãƒ†ã‚¹ãƒˆ
            queries = ["ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª" + str(i) for i in range(num_requests)]
            
            throughput_start = time.time()
            
            # ä¸¦åˆ—å®Ÿè¡Œã§ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¸¬å®š
            tasks = []
            for query in queries:
                task = asyncio.create_task(slm.generate(query))
                tasks.append(task)
            
            responses = await asyncio.gather(*tasks)
            throughput_time = time.time() - throughput_start
            
            # å…¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç¢ºèª
            for response in responses:
                assert response is not None
                assert len(response) > 0
            
            throughput = num_requests / throughput_time
            
            duration = time.time() - start_time
            message = f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.2f} req/s ({num_requests}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ)"
            print_result("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ", True, message, duration)
            
            test_results["performance_metrics"]["throughput"] = throughput
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_memory_efficiency(self):
        """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            
            # åˆæœŸãƒ¡ãƒ¢ãƒªæ¸¬å®š
            initial_memory = measure_memory()
            
            slm = DistributedSLM(config)
            
            # è¤‡æ•°å›å®Ÿè¡Œã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
            for i in range(3):
                response = await slm.generate(f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª{i}")
                assert response is not None
            
            # æœ€çµ‚ãƒ¡ãƒ¢ãƒªæ¸¬å®š
            final_memory = measure_memory()
            
            memory_increase = final_memory["rss"] - initial_memory["rss"]
            
            duration = time.time() - start_time
            message = f"ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_increase:.1f}MB (RSS: {final_memory['rss']:.1f}MB)"
            
            # ãƒ¡ãƒ¢ãƒªå¢—åŠ ãŒéåº¦ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆ1GBæœªæº€ï¼‰
            memory_ok = memory_increase < 1024
            print_result("ãƒ¡ãƒ¢ãƒªåŠ¹ç‡", memory_ok, message, duration)
            
            test_results["memory_usage"]["test_memory_efficiency"] = {
                "initial": initial_memory,
                "final": final_memory,
                "increase": memory_increase
            }
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ãƒ¡ãƒ¢ãƒªåŠ¹ç‡", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_memory_management(self):
        """ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        print_header("ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
        await self._test_memory_leak()
        
        # 2. ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
        await self._test_garbage_collection()
    
    async def _test_memory_leak(self):
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            
            memory_samples = []
            
            # è¤‡æ•°å›ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆãƒ»ç ´æ£„
            for i in range(3):
                slm = DistributedSLM(config)
                await slm.generate("çŸ­ã„ãƒ†ã‚¹ãƒˆ")
                
                current_memory = measure_memory()
                memory_samples.append(current_memory["rss"])
                
                # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ˜ç¤ºçš„ã«å‰Šé™¤
                del slm
                gc.collect()
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–ã‚’ç¢ºèª
            memory_trend = memory_samples[-1] - memory_samples[0]
            
            duration = time.time() - start_time
            message = f"ãƒ¡ãƒ¢ãƒªå¤‰åŒ–: {memory_trend:.1f}MB (ã‚µãƒ³ãƒ—ãƒ«: {len(memory_samples)})"
            
            # å¤§å¹…ãªãƒ¡ãƒ¢ãƒªå¢—åŠ ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
            no_major_leak = abs(memory_trend) < 500  # 500MBæœªæº€ã®å¤‰åŒ–
            print_result("ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯", no_major_leak, message, duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_garbage_collection(self):
        """ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            
            # GCå‰ã®ãƒ¡ãƒ¢ãƒª
            gc.collect()
            memory_before = measure_memory()
            
            # å¤§é‡ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
            slm_instances = []
            for i in range(2):
                slm = DistributedSLM(config)
                slm_instances.append(slm)
            
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‰Šé™¤ã¨GC
            del slm_instances
            gc.collect()
            
            memory_after = measure_memory()
            
            memory_freed = memory_before["rss"] - memory_after["rss"]
            
            duration = time.time() - start_time
            message = f"GCåŠ¹æœ: {memory_freed:.1f}MBè§£æ”¾"
            print_result("ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³", True, message, duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def test_end_to_end(self):
        """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        print_header("ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ", 2)
        
        # 1. å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
        await self._test_complete_workflow()
        
        # 2. è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ
        await self._test_complex_scenarios()
    
    async def _test_complete_workflow(self):
        """å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["use_parallel"] = True
            config["use_summary"] = True
            config["num_agents"] = 2
            config["iterations"] = 1
            
            slm = DistributedSLM(config)
            
            # å®Ÿéš›çš„ãªè³ªå•
            question = "äººå·¥çŸ¥èƒ½ãŒç¤¾ä¼šã«ä¸ãˆã‚‹å½±éŸ¿ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
            response = await slm.generate(question)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å“è³ªç¢ºèª
            assert response is not None
            assert len(response) > 50  # ååˆ†ãªé•·ã•
            assert isinstance(response, str)
            
            duration = time.time() - start_time
            message = f"å¿œç­”é•·: {len(response)}æ–‡å­—"
            print_result("å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", True, message, duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def _test_complex_scenarios(self):
        """è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        start_time = time.time()
        try:
            config = BASE_CONFIG.copy()
            config["num_agents"] = 3
            config["iterations"] = 2
            config["use_parallel"] = True
            config["use_summary"] = True
            
            slm = DistributedSLM(config)
            
            # è¤‡é›‘ãªè³ªå•
            complex_question = "æ©Ÿæ¢°å­¦ç¿’ã€æ·±å±¤å­¦ç¿’ã€äººå·¥çŸ¥èƒ½ã®é•ã„ã¨é–¢ä¿‚æ€§ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®æ­´å²çš„ç™ºå±•ã‚‚å«ã‚ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„"
            response = await slm.generate(complex_question)
            
            assert response is not None
            assert len(response) > 100
            
            duration = time.time() - start_time
            message = f"è¤‡é›‘ã‚¯ã‚¨ãƒªå‡¦ç†å®Œäº† (å¿œç­”: {len(response)}æ–‡å­—)"
            print_result("è¤‡é›‘ã‚·ãƒŠãƒªã‚ª", True, message, duration)
            
        except Exception as e:
            duration = time.time() - start_time
            print_result("è¤‡é›‘ã‚·ãƒŠãƒªã‚ª", False, f"ã‚¨ãƒ©ãƒ¼: {e}", duration)
    
    async def cleanup_and_report(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ"""
        print_header("ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ", 1)
        
        # å®Ÿè¡Œæ™‚é–“è¨ˆç®—
        total_time = time.time() - self.start_time
        test_results["total_time"] = total_time
        
        # æœ€çµ‚ãƒ¡ãƒ¢ãƒªæ¸¬å®š
        final_memory = measure_memory()
        test_results["memory_usage"]["final"] = final_memory
        
        # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
        total_tests = len(test_results["passed"]) + len(test_results["failed"]) + len(test_results["skipped"])
        passed_tests = len(test_results["passed"])
        failed_tests = len(test_results["failed"])
        skipped_tests = len(test_results["skipped"])
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        print(f"æˆåŠŸ: {passed_tests} ({'âœ“' if failed_tests == 0 else 'âš '})")
        print(f"å¤±æ•—: {failed_tests} ({'âœ“' if failed_tests == 0 else 'âœ—'})")
        print(f"ã‚¹ã‚­ãƒƒãƒ—: {skipped_tests}")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        print(f"æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {final_memory['rss']:.1f}MB")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›
        if test_results["performance_metrics"]:
            print("\nãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
            for metric, value in test_results["performance_metrics"].items():
                print(f"  {metric}: {value:.3f}")
        
        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°
        if failed_tests > 0:
            print("\nå¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
            for failed_test in test_results["failed"]:
                print(f"  âœ— {failed_test['name']}: {failed_test['message']}")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for instance in self.slm_instances.values():
            del instance
        gc.collect()
        print(f"\n{'='*60}")
        if failed_tests == 0:
            print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        else:
            print(f"âš ï¸  {failed_tests}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        print(f"{'='*60}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«SLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆå†åˆ©ç”¨ã®ãŸã‚ï¼‰
_slm_instance = None

def get_slm_instance(config=None):
    """å†åˆ©ç”¨å¯èƒ½ãªSLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    global _slm_instance
    if _slm_instance is None or config is not None:
        if _slm_instance is not None:
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            del _slm_instance
            gc.collect()
        _slm_instance = DistributedSLM(config or DEFAULT_CONFIG)
    return _slm_instance

# ========== ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½“ãƒ†ã‚¹ãƒˆ ==========

class TestModules(unittest.TestCase):
    """å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        self.config = DEFAULT_CONFIG.copy()
        self.blackboard = Blackboard(self.config)
    
    def test_blackboard(self):
        """ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒ¼ãƒ‰ã®åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        # æ›¸ãè¾¼ã¿ãƒ†ã‚¹ãƒˆ
        entry = self.blackboard.write("test_key", "test_value")
        self.assertEqual(entry["key"], "test_key")
        self.assertEqual(entry["value"], "test_value")
        
        # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        value = self.blackboard.read("test_key")
        self.assertEqual(value, "test_value")
        
        # å±¥æ­´ãƒ†ã‚¹ãƒˆ
        history = self.blackboard.get_history("test_key")
        self.assertEqual(len(history), 1)
        self.assertEqual(history[0]["value"], "test_value")
    
    def test_input_reception(self):
        """å…¥åŠ›å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        input_reception = InputReception(self.config)
        result = input_reception.process("Hello, World!")
        
        # æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ
        self.assertIn("normalized", result)
        self.assertIsInstance(result["normalized"], str)
        
        # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ†ã‚¹ãƒˆ
        self.assertIn("tokens", result)
        self.assertIsInstance(result["tokens"], list)
        
        # åŸ‹ã‚è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        self.assertIn("embedding", result)
    
    def test_rag_retriever(self):
        """RAGæ¤œç´¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ€ãƒŸãƒ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰"""
        rag = RAGRetriever(self.config)
        result = rag.retrieve("ãƒ†ã‚¹ãƒˆç”¨ã‚¯ã‚¨ãƒª")
        
        # ä½•ã‚‰ã‹ã®æ–‡å­—åˆ—ãŒè¿”å´ã•ã‚Œã‚‹ã¯ãš
        self.assertIsInstance(result, str)
    
    def test_summary_engine(self):
        """è¦ç´„ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        # è»½é‡ãªãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®š
        test_config = self.config.copy()
        test_config["n_ctx"] = 1024
        
        summary_engine = SummaryEngine(test_config)
        entries = [
            {"agent": 0, "text": "ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆæ–‡ç« 1ã§ã™ã€‚AIã®å°†æ¥æ€§ã«ã¤ã„ã¦è­°è«–ã—ã¾ã™ã€‚"},
            {"agent": 1, "text": "ãƒ†ã‚¹ãƒˆæ–‡ç« 2ã§ã™ã€‚æŠ€è¡“ã®ç™ºå±•ã¯äººé¡ã«æ©æµã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚"}
        ]
        result = summary_engine.summarize_blackboard(entries)
        
        # è¦ç´„ã¯ç©ºã§ãªã„ã¯ãš
        self.assertIsInstance(result, str)
        self.assertTrue(len(result) > 0)

# ========== çµ±åˆãƒ†ã‚¹ãƒˆ ==========

async def test_integration():
    """åˆ†æ•£SLMã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    logging.info("çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
    start_time = time.time()
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆ©ç”¨
    slm = get_slm_instance()
    init_time = time.time() - start_time
    logging.info(f"åˆæœŸåŒ–æ™‚é–“: {init_time:.2f}ç§’")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã‚¯ã‚¨ãƒªã®å‰Šæ¸›
    test_queries = [
        "AIã¯æ•™è‚²ã‚’ã©ã®ã‚ˆã†ã«å¤‰ãˆã¾ã™ã‹ï¼Ÿ"
    ]
    
    for query in test_queries:
        logging.info(f"ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª: {query}")
        
        start_time = time.time()
        response = await slm.generate(query)
        gen_time = time.time() - start_time
        
        logging.info(f"ç”Ÿæˆæ™‚é–“: {gen_time:.2f}ç§’")
        logging.info(f"å¿œç­”: {response[:100]}...")
        
        # é»’æ¿å†…å®¹ã®ç¢ºèª
        bb_entries = len(slm.blackboard.history)
        logging.info(f"é»’æ¿ã‚¨ãƒ³ãƒˆãƒªæ•°: {bb_entries}")
    
    logging.info("çµ±åˆãƒ†ã‚¹ãƒˆçµ‚äº†")
    return True

# ========== æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ==========

async def test_iterative_summary():
    """åå¾©ã¨è¦ç´„æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print_header("åå¾©ã¨è¦ç´„ãƒ†ã‚¹ãƒˆ")
    
    # è¨­å®š: 2å›ã®åå¾©ã¨è¦ç´„æœ‰åŠ¹
    config = DEFAULT_CONFIG.copy()
    config["iterations"] = 1  # åå¾©å›æ•°ã‚’æ¸›ã‚‰ã™
    config["use_summary"] = True
    config["num_agents"] = 2
    
    print(f"è¨­å®š: {config['iterations']}å›åå¾©, è¦ç´„æœ‰åŠ¹, {config['num_agents']}ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    
    # æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ›´æ–°
    slm = get_slm_instance(config)
    query = "æ°—å€™å¤‰å‹•ã®è§£æ±ºç­–ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¦ãã ã•ã„"
    
    print(f"å…¥åŠ›: {query}")
    start_time = time.time()
    response = await slm.generate(query)
    total_time = time.time() - start_time
    
    print(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
    print(f"å‡ºåŠ›ã®ä¸€éƒ¨: {response[:100]}...")
    
    # ä¸­é–“è¦ç´„ã®ç¢ºèª
    for i in range(config["iterations"]):
        summary = slm.blackboard.read(f'summary_{i}')
        if summary:
            print(f"åå¾©{i+1}ã®è¦ç´„: {summary[:100]}...")
    
    return True

async def test_parallel_processing():
    """ä¸¦åˆ—å‡¦ç†æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print_header("ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ")
    
    # è¨­å®š: ä¸¦åˆ—å‡¦ç†æœ‰åŠ¹ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°å¢—åŠ 
    config = DEFAULT_CONFIG.copy()
    config["use_parallel"] = True
    config["num_agents"] = 2  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°å‰Šæ¸›
    config["iterations"] = 1
    
    print(f"è¨­å®š: ä¸¦åˆ—å‡¦ç†æœ‰åŠ¹, {config['num_agents']}ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    
    # åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§è¨­å®šå¤‰æ›´ã—ã¦å®Ÿè¡Œï¼ˆé€æ¬¡ï¼‰
    slm = get_slm_instance(config)
    config["use_parallel"] = False
    slm.use_parallel = False
    
    query = "è¤‡é›‘ãªå“²å­¦çš„å•é¡Œ: æ„è­˜ã¨ã¯ä½•ã‹ï¼Ÿ"
    print(f"å…¥åŠ›: {query}")
    
    # é€æ¬¡å‡¦ç†
    print("é€æ¬¡å‡¦ç†å®Ÿè¡Œä¸­...")
    start_time = time.time()
    response_normal = await slm.generate(query)
    normal_time = time.time() - start_time
    print(f"é€æ¬¡å‡¦ç†æ™‚é–“: {normal_time:.2f}ç§’")
    
    # åŒã˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ä¸¦åˆ—å‡¦ç†ã«åˆ‡ã‚Šæ›¿ãˆ
    slm.use_parallel = True
    
    # ä¸¦åˆ—å‡¦ç†
    print("ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œä¸­...")
    start_time = time.time()
    response_parallel = await slm.generate(query)
    parallel_time = time.time() - start_time
    print(f"ä¸¦åˆ—å‡¦ç†æ™‚é–“: {parallel_time:.2f}ç§’")
    
    # é€Ÿåº¦æ¯”è¼ƒ
    if normal_time > 0:
        speedup = normal_time / parallel_time
        print(f"é€Ÿåº¦å‘ä¸Šç‡: {speedup:.2f}å€")
    
    return True

# ========== RAG ZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ ==========

async def test_rag_zim_mode():
    """RAGãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®ZIMãƒ¢ãƒ¼ãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ"""
    print_header("RAGãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ ZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ")
    
    # è¨­å®š: ZIMãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹
    config = DEFAULT_CONFIG.copy()
    config["rag_mode"] = "zim"
    config["zim_path"] = "C:\\Users\\admin\\Desktop\\èª²é¡Œç ”ç©¶\\KNOWAGE_DATABASE\\wikipedia_en_top_nopic_2025-03.zim"
    config["rag_score_threshold"] = 0.5
    config["rag_top_k"] = 3
    config["debug"] = True
    
    try:
        # RAGãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®åˆæœŸåŒ–
        print(f"ZIMãƒ•ã‚¡ã‚¤ãƒ«: {config['zim_path']}")
        print("RAGãƒªãƒˆãƒªãƒ¼ãƒãƒ¼åˆæœŸåŒ–ä¸­...")
        rag = RAGRetriever(config)        # ãƒ¢ãƒ¼ãƒ‰ã®ç¢ºèª
        print(f"å®Ÿéš›ã®å‹•ä½œãƒ¢ãƒ¼ãƒ‰: {rag.mode}")
        
        if rag.mode != "zim":
            print("è­¦å‘Š: ZIMãƒ¢ãƒ¼ãƒ‰ã§ã¯ãªãä»–ã®ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ç†ç”±ãŒè€ƒãˆã‚‰ã‚Œã¾ã™:")
            print("- ZIMãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")
            print("- libzimãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„")
            print("- sentence-transformersãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„")
            return False
        
        # ã„ãã¤ã‹ã®ã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ
        test_queries = [
            "What is artificial intelligence?",
            "å¤ªé™½ç³»ã«ã¤ã„ã¦æ•™ãˆã¦",
            "Albert Einstein's theory of relativity"
        ]
        
        for query in test_queries:
            print(f"\nã‚¯ã‚¨ãƒª: {query}")
            print("-" * 40)
            result = rag.retrieve(query)
            print(f"çµæœ: \n{result[:300]}...")  # é•·ã„çµæœã¯çœç•¥
            print("-" * 40)
        
        print("\nZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆå®Œäº†")
        return True
        
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

# ========== æ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ==========

async def test_answer_quality():
    """å›ç­”ã®é©åˆ‡ã•æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print_header("è³ªå•é©åˆ‡æ€§ãƒ†ã‚¹ãƒˆ")
    
    config = DEFAULT_CONFIG.copy()
    config["iterations"] = 1
    config["num_agents"] = 2
    
    slm = get_slm_instance(config)
    
    # è³ªå•ã®é©åˆ‡æ€§ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹è³ªå•ãƒªã‚¹ãƒˆ
    test_questions = [
        "AIã¯æ•™è‚²ã‚’ã©ã®ã‚ˆã†ã«å¤‰ãˆã‚‹ã¨æ€ã†ï¼Ÿ",  # å®Ÿè¡Œã‚¿ã‚¹ã‚¯ã®ä¾‹
        "åœ°çƒæ¸©æš–åŒ–ã®ä¸»ãªåŸå› ã¯ä½•ã§ã™ã‹ï¼Ÿ",     # æ˜ç¢ºãªäº‹å®Ÿè³ªå•
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã®å°†æ¥æ€§ã«ã¤ã„ã¦",     # æŠ€è¡“äºˆæ¸¬è³ªå•
    ]
    
    for i, question in enumerate(test_questions):
        print(f"\nè³ªå• {i+1}: {question}")
        print("-" * 40)
        
        start_time = time.time()
        response = await slm.generate(question)
        gen_time = time.time() - start_time
        
        print(f"å¿œç­”æ™‚é–“: {gen_time:.2f}ç§’")
        print(f"å¿œç­”: \n{response}")
        print("-" * 40)
    
    return True

async def test_conversation_memory():
    """ä¼šè©±è¨˜æ†¶æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print_header("ä¼šè©±å±¥æ­´è¨˜æ†¶ãƒ†ã‚¹ãƒˆ")
    
    config = DEFAULT_CONFIG.copy()
    config["iterations"] = 1
    config["num_agents"] = 2
    config["use_memory"] = True  # ä¼šè©±å±¥æ­´æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
    
    # æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§è¨˜æ†¶ã‚’ã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã‹ã‚‰å§‹ã‚ã‚‹
    slm = get_slm_instance(config)
    
    # è¨˜æ†¶ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆç›´æ¥conversation_memoryã‚’ä½¿ç”¨ï¼‰
    if hasattr(slm, 'conversation_memory'):
        slm.conversation_memory.clear_memory()
        print("ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    # ä¼šè©±ã®æµã‚Œã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹è³ªå•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
    conversation = [
        "ã“ã‚“ã«ã¡ã¯ã€ç§ã®åå‰ã¯åœ’æœ¨ã§ã™ã€‚",
        "ç§ã®è¶£å‘³ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ",
        "ç§ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨ãƒ”ã‚¢ãƒãŒå¥½ãã§ã™ã€‚",
        "ç§ã®åå‰ã¯ä½•ã§ã—ãŸã‹ï¼Ÿ",  # ä»¥å‰ã®ä¼šè©±ã‚’è¦šãˆã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
    ]
    
    for i, message in enumerate(conversation):
        print(f"\nä¼šè©±ã‚¿ãƒ¼ãƒ³ {i+1}: {message}")
        print("-" * 40)
        
        response = await slm.generate(message)
        print(f"å¿œç­”: {response}")
        
        # ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®çŠ¶æ…‹ã‚’è¡¨ç¤º
        if i > 0 and 'conversation_context' in slm.blackboard.memory:
            context = slm.blackboard.read('conversation_context')
            print(f"ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}")
    
    return True

async def test_role_assignment():
    """å½¹å‰²æŒ¯ã‚Šåˆ†ã‘ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ"""
    print_header("å½¹å‰²æŒ¯ã‚Šåˆ†ã‘ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ")
    
    config = DEFAULT_CONFIG.copy()
    config["iterations"] = 1
    config["num_agents"] = 3  # ã‚ˆã‚Šå¤šãã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å¤šæ§˜ãªå½¹å‰²ã‚’ç¢ºèª
    
    slm = get_slm_instance(config)
    
    # ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®è³ªå•ã§ãƒ†ã‚¹ãƒˆ
    test_questions = [
        {"text": "AIã¨äººé–“ã®å”èª¿ã¨ç«¶äº‰ã«ã¤ã„ã¦è­°è«–ã—ã¦ãã ã•ã„", "type": "discussion"},
        {"text": "æ–°ã—ã„ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã®ãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ©ãƒ³ã‚’è€ƒãˆã¦ãã ã•ã„", "type": "planning"},
        {"text": "é‡å­åŠ›å­¦ã®åŸºæœ¬åŸç†ã‚’ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„", "type": "informational"},
        {"text": "ä»Šæ—¥ã®æ°—åˆ†ã¯ã©ã†ã§ã™ã‹ï¼Ÿ", "type": "conversational"},
    ]
    
    for i, question_data in enumerate(test_questions):
        question = question_data["text"]
        expected_type = question_data["type"]
        
        print(f"\nè³ªå• {i+1}: {question}")
        print(f"æœŸå¾…ã•ã‚Œã‚‹è³ªå•ã‚¿ã‚¤ãƒ—: {expected_type}")
        print("-" * 40)
        
        # è³ªå•ã‚¿ã‚¤ãƒ—ã¨å½¹å‰²ã®åˆ¤å®š
        normalized_question = {"normalized": question}
        slm.blackboard.write('input', normalized_question)
        slm.agent_pool.update_roles_based_on_question(question)
        
        # å®Ÿéš›ã«åˆ¤å®šã•ã‚ŒãŸè³ªå•ã‚¿ã‚¤ãƒ—ã‚’è¡¨ç¤º
        actual_type = slm.blackboard.read('question_type')
        print(f"åˆ¤å®šã•ã‚ŒãŸè³ªå•ã‚¿ã‚¤ãƒ—: {actual_type}")
        
        # é¸æŠã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå½¹å‰²ã‚’è¡¨ç¤º
        print("é¸æŠã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå½¹å‰²:")
        for j in range(slm.num_agents):
            role_idx = j % len(slm.agent_pool.agent_roles)
            role = slm.agent_pool.agent_roles[role_idx]
            print(f"  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ{j+1}: {role['role']}")
        
        # å¿œç­”ç”Ÿæˆ
        response = await slm.generate(question)
        print(f"å¿œç­”: {response[:150]}...")  # é•·ã„å ´åˆã¯çœç•¥
    
    return True

async def test_blackboard_conversation_memory():
    """é»’æ¿ã¨çµ±åˆã—ãŸä¼šè©±è¨˜æ†¶ãƒ†ã‚¹ãƒˆ"""
    print_header("é»’æ¿ã¨çµ±åˆã—ãŸä¼šè©±è¨˜æ†¶ãƒ†ã‚¹ãƒˆ")
    
    # è¨­å®š
    config = DEFAULT_CONFIG.copy()
    config["use_memory"] = True
    
    # æ–°ã—ã„é»’æ¿ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
    blackboard = Blackboard(config)
    
    # ä¼šè©±è¨˜æ†¶ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é»’æ¿ã¨çµ±åˆã—ã¦ä½œæˆ
    conversation_memory = ConversationMemory(config, blackboard=blackboard)
    
    print("ä¼šè©±è¨˜æ†¶ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é»’æ¿ã¨çµ±åˆã—ã¾ã—ãŸ")
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿
    test_conversations = [
        # (ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›, ã‚·ã‚¹ãƒ†ãƒ å¿œç­”)
        ("ã“ã‚“ã«ã¡ã¯ã€ç§ã®åå‰ã¯å¤ªéƒã§ã™ã€‚", "å¤ªéƒã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ"),
        ("æ±äº¬ã«ä½ã‚“ã§ã„ã¾ã™ã€‚", "æ±äº¬ã¯ç´ æ™´ã‚‰ã—ã„éƒ½å¸‚ã§ã™ã­ã€‚ä½•ã‹æ±äº¬ã«ã¤ã„ã¦è³ªå•ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"),
        ("è¶£å‘³ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã§ã™ã€‚", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯ç´ æ™´ã‚‰ã—ã„è¶£å‘³ã§ã™ã­ã€‚ã©ã‚“ãªè¨€èªã‚’ä½¿ã„ã¾ã™ã‹ï¼Ÿ"),
        ("PythonãŒå¥½ãã§ã™ã€‚", "Pythonã¯æ±ç”¨æ€§ãŒé«˜ãç´ æ™´ã‚‰ã—ã„è¨€èªã§ã™ã­ï¼ä½•ã‹ä½œã£ã¦ã„ã‚‹ã‚‚ã®ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ")
    ]
    
    # ä¼šè©±ã‚’é †ç•ªã«è¿½åŠ 
    print("\nä¼šè©±ã®è¿½åŠ :")
    for i, (user_input, system_response) in enumerate(test_conversations):
        print(f"\nä¼šè©± {i+1}:")
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}")
        print(f"ã‚·ã‚¹ãƒ†ãƒ : {system_response}")
        
        # ä¼šè©±ã‚’è¨˜æ†¶ã«è¿½åŠ 
        conversation_memory.add_conversation_entry(user_input, system_response)
        
        # é»’æ¿ã«ä¿å­˜ã•ã‚ŒãŸå†…å®¹ã‚’ç¢ºèª
        print("\né»’æ¿ã®çŠ¶æ…‹ç¢ºèª:")
        if blackboard.read("conversation_history"):
            print(f"- å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(blackboard.read('conversation_history'))}")
        if blackboard.read("conversation_context"):
            context = blackboard.read("conversation_context")
            print(f"- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context[:100]}...")
        if blackboard.read("conversation_key_facts"):
            facts = blackboard.read("conversation_key_facts")
            print("- æŠ½å‡ºã•ã‚ŒãŸé‡è¦ãªæƒ…å ±:")
            for category, items in facts.items():
                if items:
                    print(f"  {category}: {', '.join(items)}")
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ãƒ†ã‚¹ãƒˆ
    context = conversation_memory.get_conversation_context()
    print("\næœ€çµ‚çš„ãªä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(f"{context[:200]}...")
    
    # é‡è¦æƒ…å ±ã®å–å¾—ãƒ†ã‚¹ãƒˆ
    key_facts = conversation_memory.key_facts
    print("\næŠ½å‡ºã•ã‚ŒãŸé‡è¦æƒ…å ±:")
    for category, items in key_facts.items():
        if items:
            print(f"{category}: {', '.join(items)}")
    
    # æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    print("\næ–°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§é»’æ¿ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ:")
    new_memory = ConversationMemory(config, blackboard=blackboard)
    print(f"- å±¥æ­´ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(new_memory.conversation_history)}")
    print(f"- åå‰ã®è¨˜æ†¶: {new_memory.key_facts.get('names', [])}")
    
    return True

# ========== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ==========

def print_header(title):
    """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ã®è¡¨ç¤º"""
    print("\n" + "="*50)
    print(f"  {title}")
    print("="*50)

async def main():
    """ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print_header("MurmurNet ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    
    try:
        # é»’æ¿ã¨ä¼šè©±è¨˜æ†¶ã®çµ±åˆãƒ†ã‚¹ãƒˆ (æ–°è¦è¿½åŠ )
        await test_blackboard_conversation_memory()
        
        # æ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆï¼ˆè¿½åŠ ï¼‰
        print_header("æ–°å®Ÿè£…æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        
        # 1. è³ªå•é©åˆ‡æ€§ãƒ†ã‚¹ãƒˆ
        await test_answer_quality()
        
        # 2. ä¼šè©±è¨˜æ†¶ãƒ†ã‚¹ãƒˆ
        await test_conversation_memory()
        
        # 3. å½¹å‰²æŒ¯ã‚Šåˆ†ã‘ãƒ†ã‚¹ãƒˆ
        await test_role_assignment()
        
        # æ—¢å­˜ãƒ†ã‚¹ãƒˆ
        # RAG ZIMãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆï¼ˆè¿½åŠ ï¼‰
        print_header("RAG ZIMãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ")
        await test_rag_zim_mode()
        
        # é †åºã‚’å¤‰æ›´ï¼šçµ±åˆãƒ†ã‚¹ãƒˆâ†’æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆâ†’å˜ä½“ãƒ†ã‚¹ãƒˆã®é †ã§
        
        # çµ±åˆãƒ†ã‚¹ãƒˆ 
        print_header("çµ±åˆãƒ†ã‚¹ãƒˆ")
        success = await test_integration()
        if success:
            print("âœ“ çµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
        else:
            print("âœ— çµ±åˆãƒ†ã‚¹ãƒˆå¤±æ•—")
        
        # åå¾©ã¨è¦ç´„ã®ãƒ†ã‚¹ãƒˆ
        await test_iterative_summary()
        
        # ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
        await test_parallel_processing()
        
        # å˜ä¸€ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆï¼ˆæœ€çµ‚ãƒã‚§ãƒƒã‚¯ï¼‰
        print_header("å˜ä¸€ã‚¯ã‚¨ãƒªãƒ†ã‚¹ãƒˆ (æœ€çµ‚)")
        config = DEFAULT_CONFIG.copy()
        config["iterations"] = 1  # åå¾©å›æ•°ã‚’æ¸›ã‚‰ã™
        config["use_summary"] = True
        config["num_agents"] = 2  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ•°å‰Šæ¸›
        config["use_memory"] = True  # ä¼šè©±å±¥æ­´ã‚’æœ‰åŠ¹åŒ–
        
        # æ—¢å­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ›´æ–°
        slm = get_slm_instance(config)
        
        query = "äººå·¥çŸ¥èƒ½ã¨äººé–“ã®é–¢ä¿‚ã¯ã©ã®ã‚ˆã†ã«ç™ºå±•ã™ã‚‹ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
        print(f"å…¥åŠ›: {query}")
        
        response = await slm.generate(query)
        print(f"å‡ºåŠ›: {response}")
        
        # æœ€å¾Œã«å˜ä½“ãƒ†ã‚¹ãƒˆï¼ˆLLMã‚’ä½¿ã‚ãªã„è»½é‡ãƒ†ã‚¹ãƒˆï¼‰
        print_header("ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½“ãƒ†ã‚¹ãƒˆ")
        unittest.main(argv=['first-arg-is-ignored'], exit=False)
        
        # ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾
        global _slm_instance
        if (_slm_instance is not None):
            del _slm_instance
            _slm_instance = None
            gc.collect()
        
        print("\nãƒ†ã‚¹ãƒˆå®Œäº†")
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
